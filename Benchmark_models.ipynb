{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97aebc4f",
   "metadata": {},
   "source": [
    "# Benchmark model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ba263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import os\n",
    "\n",
    "\n",
    "# Views 3\n",
    "import views_runs\n",
    "from viewser.operations import fetch\n",
    "from views_forecasts.extensions import *\n",
    "from viewser import Queryset, Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters:\n",
    "\n",
    "dev_id = 'Fatalities002'\n",
    "run_id = 'Fatalities002'\n",
    "EndOfHistory = 508\n",
    "get_future = False\n",
    "\n",
    "username = os.getlogin()\n",
    "\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "\n",
    "fi_steps = [1,3,6,12,36]\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,396),\"predict\":(397,444)}\n",
    "test_partitioner_dict = {\"train\":(121,444),\"predict\":(445,492)}\n",
    "future_partitioner_dict = {\"train\":(121,492),\"predict\":(493,504)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = f'/Users/{username}/Dropbox (ViEWS)/ViEWS/'\n",
    "overleafpath = f'/Users/{username}/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/Tables/'\n",
    "\n",
    "\n",
    "\n",
    "print('Dropbox path set to',Mydropbox)\n",
    "print('Overleaf path set to',overleafpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a787408",
   "metadata": {},
   "source": [
    "## cm level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8bd551",
   "metadata": {},
   "source": [
    "### Based on constituent models\n",
    "\n",
    "Short version, 22 models: \n",
    "1 \"draw\"\n",
    "from each of 22 constituent models\n",
    "\n",
    "Long version, 440 models:\n",
    "20 \"draws\" from each of 22 constituent models, using predictions for adjacent steps (from s-4 to s+6). Some duplications to weight the most proximate steps more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989b764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fatalities002 stuff - contains the list of the current fatalities002 ensemble models\n",
    "\n",
    "from ModelDefinitions import DefineEnsembleModels\n",
    "\n",
    "level = 'cm'\n",
    "ModelList_cm = DefineEnsembleModels(level)\n",
    "    \n",
    "i = 0\n",
    "for model in ModelList_cm:\n",
    "    print(i, model['modelname'], model['data_train'])\n",
    "    i = i + 1\n",
    "\n",
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "\n",
    "ModelList_cm = RetrieveStoredPredictions(ModelList_cm, steps, EndOfHistory, dev_id, level, get_future)\n",
    "\n",
    "ModelList_cm = CalibratePredictions(ModelList_cm, EndOfHistory, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3358741",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelList_cm[0]['predictions_test_df']\n",
    "ModelList_cm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a00e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with actuals\n",
    "df_actuals = pd.DataFrame(ModelList_cm[0]['predictions_test_df']['ln_ged_sb_dep'])\n",
    "print(df_actuals.head())\n",
    "print(df_actuals.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcb7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_df_cm(df, draw):\n",
    "    ''' Drops steps we will not need in the benchmark model. \n",
    "    Another round of drops are done below '''\n",
    "    steps_to_drop = ['ln_ged_sb_dep','step_pred_23','step_pred_24',\n",
    "                     'step_pred_25','step_pred_26','step_pred_27','step_pred_28','step_pred_29','step_pred_30',\n",
    "                     'step_pred_31','step_pred_32','step_pred_33','step_pred_34','step_pred_35','step_pred_36',]\n",
    "    df = df.drop(steps_to_drop,axis=1)\n",
    "    df.reset_index(inplace=True)\n",
    "    df['draw'] = draw\n",
    "    df_long = pd.wide_to_long(df, 'step_pred_', i = ['month_id', 'country_id', 'draw'], j = 'step')\n",
    "    return(df_long)\n",
    "    \n",
    "model_draw = 0\n",
    "df = ModelList_cm[model_draw]['predictions_test_df'].copy()\n",
    "df_cm_results_long = reshape_df_cm(df,model_draw)\n",
    "print('Starting with model/draw',model_draw, model['modelname'])\n",
    "print(df_cm_results_long.describe())\n",
    "\n",
    "\n",
    "for model in ModelList_cm[1:]:\n",
    "    model_draw += 1\n",
    "    print('Appending model/draw',model_draw, model['modelname'])\n",
    "    df = ModelList_cm[model_draw]['predictions_test_df'].copy()\n",
    "    df_reshaped = reshape_df_cm(df,model_draw)\n",
    "    df_cm_results_long = pd.concat([df_cm_results_long ,df_reshaped], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe118d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_results_long['prediction'] = np.round_(np.expm1(df_cm_results_long['step_pred_'])).astype('int32')\n",
    "df_cm_results_long.drop(columns=['step_pred_'], inplace=True)\n",
    "# Results file in long format\n",
    "print(df_cm_results_long.describe())\n",
    "print(df_cm_results_long.tail())\n",
    "\n",
    "print(df_cm_results_long.loc[492].describe())\n",
    "\n",
    "# Extending by copying adjacent steps\n",
    "\n",
    "df_cm_results_extended=df_cm_results_long.copy()\n",
    "print(df_cm_results_extended.describe())\n",
    "print(df_cm_results_extended.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1871a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_final_extended = df_cm_results_extended.copy()\n",
    "\n",
    "def make_dfcopy(df_in, step, shifted_step, repetition):\n",
    "    ''' Makes a 'copy' of the df with a shifted step '''\n",
    "#    print(step, shifted_step, repetition)\n",
    "    df = pd.DataFrame(df_in[df_in.index.get_level_values('step').isin([shifted_step])]).copy()\n",
    "    df.reset_index(inplace = True)\n",
    "    df['step'].replace(shifted_step, step, inplace = True)\n",
    "#    print(df.describe())\n",
    "    df['draw'] = (df['draw'] + len(ModelList) * repetition)\n",
    "#    print(df.describe())\n",
    "    df.set_index(['month_id', 'country_id', 'step', 'draw'], inplace=True)\n",
    "    return(df)\n",
    "    \n",
    "df_list_steps = []\n",
    "for step in range(3,14+1):     \n",
    "#    print(80*'*')\n",
    "    print('Step', step, '-- Original dataframe for step', step, 'is:')\n",
    "    df = pd.DataFrame(df_cm_results_extended[df_cm_results_extended.index.get_level_values('step').isin([step])])\n",
    "#    print(df.head(3))\n",
    "    repetition = 1\n",
    "    df_list = []\n",
    "    for shift in [(-4,1),(-3,1),(-2,3),(-1,4),(0,3),(1,3),(2,2),(3,2),(4,1),(5,1),(6,1),(7,1),(8,1)]:\n",
    "        for copy in range(1,shift[1]+1):\n",
    "            shifted_step = step+shift[0]\n",
    "            if shifted_step < 1:\n",
    "                shifted_step = step\n",
    "            step_list = [shifted_step]\n",
    "            df = make_dfcopy(df_in = df_cm_results_extended,step = step, shifted_step = shifted_step, repetition = repetition)\n",
    "            df_list.append(df)\n",
    "            repetition += 1\n",
    "    df_cm_temp = pd.concat(df_list)\n",
    "    df_list_steps.append(df_cm_temp)\n",
    "\n",
    "df_cm_final_extended = pd.concat(df_list_steps)\n",
    "#df.reorder_levels(['month_id','country_id','steps','draw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9996a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(make_dfcopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_final_extended.loc[492].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b822a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_final_extended.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ea11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning the original down to steps 3-14\n",
    "steps_to_keep = range(3,15)\n",
    "\n",
    "df_cm_results_long_pruned = df_cm_results_long[df_cm_results_long.index.get_level_values('step').isin(steps_to_keep)]\n",
    "df_cm_results_long_pruned.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d92db",
   "metadata": {},
   "source": [
    "### cm last historical values benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c89361",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = (Queryset(\"benchmark_cm\", \"country_month\")\n",
    "\n",
    "   # target variable\n",
    "   .with_column(Column(\"ged_sb\", from_table=\"ged2_cm\", from_column=\"ged_sb_best_sum_nokgi\")\n",
    "                .transform.missing.fill()\n",
    "                .transform.missing.replace_na()\n",
    "                )\n",
    "\n",
    "\n",
    "   .with_theme(\"benchmark\")\n",
    "   .describe(\"\"\"Data for empirical benchmark model, cm level\n",
    "\n",
    "\n",
    "            \"\"\")\n",
    "   )\n",
    "\n",
    "#queryset = Queryset(\"name\", \"loa\") # if not already defined\n",
    "column = \"ged_sb_best_sum_nokgi\"\n",
    "table = \"ged2_cm\"\n",
    "lags=range(1,65)\n",
    "for lag in lags: \n",
    "    qs = qs.with_column(Column(column+'_' + str(lag), from_table = table, from_column=column)\n",
    "                        .transform.missing.replace_na()\n",
    "                        .transform.temporal.tlag(lag)\n",
    "                       )\n",
    "df_cm_historical_values = qs.publish().fetch()\n",
    "df_cm_historical_values = df_cm_historical_values.loc[445:492]\n",
    "\n",
    "df_cm_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating predictions for test partition\n",
    "number_of_lags = 45\n",
    "maxstep = 14\n",
    "df_list_bystep = []\n",
    "for step in range(3,maxstep+1):\n",
    "    lags=range(step,step + number_of_lags)\n",
    "    draw = 1\n",
    "    print('step:',step,'lag:',lag, 'draw:',draw)\n",
    "    df_list = []\n",
    "    for lag in lags:\n",
    "        number_of_repetitions = number_of_lags+step-lag\n",
    "#        print('lag:',lag,'repetitions:',number_of_repetitions)\n",
    "#        print('step:',step,'lag:',lag, 'draw:',draw)\n",
    "        for repetition in range(1,number_of_repetitions):\n",
    "            lagged_col = 'ged_sb_best_sum_nokgi_' + str(lag)\n",
    "            df = pd.DataFrame(df_cm_historical_values[lagged_col].copy())\n",
    "            df.reset_index(inplace=True)\n",
    "            df['prediction'] = df[lagged_col]\n",
    "#            print(df.head())\n",
    "            df.drop(columns=[lagged_col], inplace=True)\n",
    "            df['step'] = step\n",
    "            df['draw'] = draw\n",
    "            df.set_index(['month_id', 'country_id','draw', 'step'], inplace=True)\n",
    "            df_list.append(df)\n",
    "#            if draw == 1 and step == 1:\n",
    "#                df_cm_predictions_historical_values = df.copy()\n",
    "#            else:\n",
    "#                df_cm_predictions_historical_values = pd.concat([df_cm_predictions_historical_values,df])\n",
    "            draw = draw + 1\n",
    "    df_cm_predictions_lag = pd.concat(df_list)\n",
    "    df_list_bystep.append(df_cm_predictions_lag)\n",
    "    print('Number of draws:',draw + 1)\n",
    "df_cm_predictions_historical_values = pd.concat(df_list_bystep) \n",
    "\n",
    "df_cm_predictions_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ab3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_and_categorize(df, level):\n",
    "    ''' This function aggregates the input df across all draws, and returns summary statistics for the prediction model '''\n",
    "    if level == 'cm':\n",
    "        index = ['month_id','country_id','step']\n",
    "    if level == 'pgm':\n",
    "        index = ['month_id', 'priogrid_gid','step']\n",
    "    df_to_aggregate = df.copy()\n",
    "    df_to_aggregate['log_prediction'] = np.log1p(df_to_aggregate['prediction'] )\n",
    "\n",
    "    # Proportion of draws in fatality categories\n",
    "    #for cutoffs in [0,1,10,100,1000,10000]:\n",
    "    bins = pd.IntervalIndex.from_tuples([(-1, 0), (1, 10), (11, 100), (101, 1000), (1001, 10000), (10001,100000000)])\n",
    "    df_to_aggregate['categorical'] = pd.cut(df_to_aggregate['prediction'],bins)\n",
    "    df_to_aggregate_dummies = pd.get_dummies(df_to_aggregate['categorical'],prefix='cat')\n",
    "    df_to_aggregate = pd.concat([df_to_aggregate,df_to_aggregate_dummies],axis=1)\n",
    "\n",
    "    # Mean and standard deviation of log predictions\n",
    "    df_aggregated = pd.DataFrame(df_to_aggregate['log_prediction'].groupby(level=index).mean())\n",
    "    df_aggregated.rename(columns={'log_prediction':'mean_log_prediction'},inplace=True)\n",
    "    df_aggregated['std_log_prediction'] = df_to_aggregate['log_prediction'].groupby(level=index).std()\n",
    "    for col in ('cat_(-1, 0]','cat_(1, 10]','cat_(11, 100]','cat_(101, 1000]','cat_(1001, 10000]','cat_(10001, 100000000]'):\n",
    "        df_aggregated[col] = df_to_aggregate[col].groupby(level=index).mean()\n",
    "    return(df_aggregated)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a2957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate across draws/samples to extract means, standard deviations, and category probabilities\n",
    "df_cm_predictions_historical_values_aggregated = aggregate_and_categorize(df_cm_predictions_historical_values,'cm')\n",
    "df_cm_predictions_ensemble_aggregated = aggregate_and_categorize(df_cm_final_extended,'cm')\n",
    "\n",
    "print(df_cm_predictions_historical_values_aggregated.describe())\n",
    "print(df_cm_predictions_historical_values_aggregated.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb70485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw from the aggregated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947356fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_actuals.csv'\n",
    "df_actuals.to_csv(filename)\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_ensemble_22.parquet'\n",
    "df_cm_results_long_pruned.to_parquet(filename)\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_ensemble_550.parquet'\n",
    "df_cm_final_extended.to_parquet(filename)\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_ensemble_550_aggregated.parquet'\n",
    "df_cm_predictions_ensemble_aggregated.to_parquet(filename)\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_historical_values.parquet'\n",
    "df_cm_predictions_historical_values.to_parquet(filename)\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_predictions_historical_values_aggregated.parquet'\n",
    "df_cm_predictions_historical_values_aggregated.to_parquet(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51884343",
   "metadata": {},
   "source": [
    "# pgm benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea38184",
   "metadata": {},
   "source": [
    "## Ensemble model pgm benchmark\n",
    "\n",
    "kj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e78ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "level = 'pgm'\n",
    "ModelList_pgm = DefineEnsembleModels(level)\n",
    "    \n",
    "i = 0\n",
    "for model in ModelList_pgm:\n",
    "    print(i, model['modelname'], model['data_train'])\n",
    "    i = i + 1\n",
    "    \n",
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "\n",
    "ModelList_pgm = RetrieveStoredPredictions(ModelList_pgm, steps, EndOfHistory, dev_id, level, get_future)\n",
    "\n",
    "#ModelList_pgm = CalibratePredictions(ModelList_pgm, EndOfHistory, steps)\n",
    "\n",
    "# Dataframe with actuals\n",
    "df_actuals_pgm = pd.DataFrame(ModelList_pgm[0]['predictions_test_df']['ln_ged_sb_dep'])\n",
    "print(df_actuals_pgm.head())\n",
    "print(df_actuals_pgm.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48259249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "def reshape_df_pgm(df, draw):\n",
    "    ''' Drops steps we will not need in the benchmark model. \n",
    "    Another round of drops are done below '''\n",
    "    steps_to_drop = ['ln_ged_sb_dep','step_pred_23','step_pred_24',\n",
    "                     'step_pred_25','step_pred_26','step_pred_27','step_pred_28','step_pred_29','step_pred_30',\n",
    "                     'step_pred_31','step_pred_32','step_pred_33','step_pred_34','step_pred_35','step_pred_36',]\n",
    "    df = df.drop(steps_to_drop,axis=1)\n",
    "    df.reset_index(inplace=True)\n",
    "    df['draw'] = draw\n",
    "    df_long = pd.wide_to_long(df, 'step_pred_', i = ['month_id', 'priogrid_id', 'draw'], j = 'step')\n",
    "    return(df_long)\n",
    "\n",
    "model_draw = 0\n",
    "df = ModelList_pgm[model_draw]['predictions_test_df'].copy()\n",
    "df_pgm_results_long = reshape_df_pgm(df,model_draw)\n",
    "print('Starting with model/draw',model_draw, model['modelname'])\n",
    "print(df_pgm_results_long.describe())\n",
    "\n",
    "\n",
    "for model in ModelList_pgm[1:]:\n",
    "    model_draw += 1\n",
    "    print('Appending model/draw',model_draw, model['modelname'])\n",
    "    df = ModelList_pgm[model_draw]['predictions_test_df'].copy()\n",
    "    df_reshaped = reshape_df_pgm(df,model_draw)\n",
    "    df_pgm_results_long = pd.concat([df_pgm_results_long ,df_reshaped], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084e92d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_results_long['prediction'] = np.round_(np.expm1(df_pgm_results_long['step_pred_'])).astype('int32')\n",
    "df_pgm_results_long.drop(columns=['step_pred_'], inplace=True)\n",
    "# Results file in long format\n",
    "print(df_pgm_results_long.describe())\n",
    "print(df_pgm_results_long.tail())\n",
    "\n",
    "print(df_pgm_results_long.loc[492].describe())\n",
    "\n",
    "# Extending by copying adjacent steps\n",
    "\n",
    "df_pgm_results_extended=df_pgm_results_long.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44e7811",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pgm_results_extended.describe())\n",
    "print(df_pgm_results_extended.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4549533",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_final_extended = df_pgm_results_extended.copy()\n",
    "\n",
    "def make_dfcopy_pgm(df_in, step, shifted_step, repetition):\n",
    "    ''' Makes a 'copy' of the df with a shifted step '''\n",
    "#    print(step, shifted_step, repetition)\n",
    "    df = pd.DataFrame(df_in[df_in.index.get_level_values('step').isin([shifted_step])]).copy()\n",
    "    df.reset_index(inplace = True)\n",
    "    df['step'].replace(shifted_step, step, inplace = True)\n",
    "#    print(df.describe())\n",
    "    df['draw'] = (df['draw'] + len(ModelList) * repetition)\n",
    "#    print(df.describe())\n",
    "    df.set_index(['month_id', 'priogrid_id', 'step', 'draw'], inplace=True)\n",
    "    return(df)\n",
    "    \n",
    "df_list_steps_pgm = []\n",
    "for step in range(3,14+1):     \n",
    "#    print(80*'*')\n",
    "    print('Step', step, '-- Original dataframe for step', step, 'is:')\n",
    "    df = pd.DataFrame(df_pgm_results_extended[df_pgm_results_extended.index.get_level_values('step').isin([step])])\n",
    "    print(df.head(3))\n",
    "    repetition = 1\n",
    "    df_list_pgm = []\n",
    "    for shift in [(-4,1),(-3,1),(-2,3),(-1,4),(0,3),(1,3),(2,2),(3,2),(4,1),(5,1),(6,1),(7,1),(8,1)]:\n",
    "        for copy in range(1,shift[1]+1):\n",
    "            shifted_step = step+shift[0]\n",
    "            if shifted_step < 1:\n",
    "                shifted_step = step\n",
    "            step_list = [shifted_step]\n",
    "            df = make_dfcopy_pgm(df_in = df_pgm_results_extended,step = step, shifted_step = shifted_step, repetition = repetition)\n",
    "            df_list_pgm.append(df)\n",
    "            repetition += 1\n",
    "    df_pgm_temp = pd.concat(df_list)\n",
    "    df_list_steps_pgm.append(df_cm_temp)\n",
    "\n",
    "#df_pgm_final_extended = pd.concat(df_list_steps)\n",
    "#df.reorder_levels(['month_id','country_id','steps','draw'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be4904",
   "metadata": {},
   "source": [
    "## Historical values pgm benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55417594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag settings (number of temporal lags at each spatial lag level)\n",
    "tlags_cell = 40\n",
    "tlags_firstorder = 27\n",
    "tlags_secondorder = 21\n",
    "\n",
    "# Spatial lags, first-order lag 1:\n",
    "kernel_inner=1\n",
    "kernel_width=1\n",
    "kernel_power=0\n",
    "norm_kernel=0\n",
    "\n",
    "print('Retrieving data for inner cells')\n",
    "\n",
    "column = \"ged_sb_best_sum_nokgi\"\n",
    "table = \"ged2_pgm\"\n",
    "\n",
    "qs = (Queryset(\"benchmark_pgm\", \"priogrid_month\")\n",
    "\n",
    "   # target variable at t0\n",
    "   .with_column(Column(\"ged_sb\", from_table=\"ged2_pgm\", from_column=\"ged_sb_best_sum_nokgi\")\n",
    "                .transform.missing.fill()\n",
    "                .transform.missing.replace_na()\n",
    "                )\n",
    "    # spatial lag at t0\n",
    "   .with_column(Column(\"splag_ged_sb_0\", from_table = table, from_column = column)\n",
    "                     .transform.missing.replace_na()\n",
    "                     .transform.spatial.lag(kernel_inner,kernel_width,kernel_power,norm_kernel)\n",
    "                    )\n",
    "\n",
    "\n",
    "   .with_theme(\"benchmark\")\n",
    "   .describe(\"\"\"Data for empirical benchmark model, pgm level\n",
    "\n",
    "\n",
    "            \"\"\")\n",
    "   )\n",
    "\n",
    "#queryset = Queryset(\"name\", \"loa\") # if not already defined\n",
    "column = \"ged_sb_best_sum_nokgi\"\n",
    "table = \"ged2_pgm\"\n",
    "tlags_0=range(1,tlags_cell + 1)\n",
    "qs0 = qs.copy()\n",
    "for lag in tlags_0: \n",
    "    qs0 = qs0.with_column(Column(column + '_' + str(lag), from_table = table, from_column=column)\n",
    "                        .transform.missing.replace_na()\n",
    "                        .transform.temporal.tlag(lag)\n",
    "                       )\n",
    "\n",
    "df_pgm_historical_values_0 = qs0.publish().fetch().loc[445:492]\n",
    "\n",
    "# Spatial lags, first-order:\n",
    "print('Retrieving data for first-order neighbors')\n",
    "\n",
    "\n",
    "kernel_inner=1\n",
    "kernel_width=1\n",
    "kernel_power=0\n",
    "norm_kernel=0\n",
    "\n",
    "\n",
    "tlags_1=range(1,tlags_firstorder + 1)\n",
    "qs1 = qs.copy()\n",
    "for lag in tlags_1:\n",
    "    qs1 = qs1.with_column(Column(column + '_splag_1_' + str(lag), from_table = table, from_column=column)\n",
    "                        .transform.missing.replace_na()\n",
    "                        .transform.temporal.tlag(lag)\n",
    "                        .transform.spatial.lag(kernel_inner,kernel_width,kernel_power,norm_kernel)\n",
    "                       )\n",
    "\n",
    "df_pgm_historical_values_1 = qs1.publish().fetch().loc[445:492]\n",
    "\n",
    "# Spatial lags; second-order:\n",
    "print('Retrieving data for second-order neighbors')\n",
    "\n",
    "\n",
    "kernel_inner=2\n",
    "kernel_width=1\n",
    "kernel_power=0\n",
    "norm_kernel=0\n",
    "\n",
    "tlags_2=range(1,tlags_secondorder + 1)\n",
    "qs2 = qs.copy()\n",
    "for lag in tlags_2:\n",
    "    qs2 = qs2.with_column(Column(column + '_splag_2_' + str(lag), from_table = table, from_column=column)\n",
    "                        .transform.missing.replace_na()\n",
    "                        .transform.temporal.tlag(lag)\n",
    "                        .transform.spatial.lag(kernel_inner,kernel_width,kernel_power,norm_kernel)\n",
    "                       )\n",
    "\n",
    "df_pgm_historical_values_2 = qs2.publish().fetch().loc[445:492]\n",
    "print('Done retrieving data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aabc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_historical_values_1.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ccd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the data frames\n",
    "df_pgm_historical_values = pd.concat([df_pgm_historical_values_0, df_pgm_historical_values_1, df_pgm_historical_values_2], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_historical_values = df_pgm_historical_values.loc[445:492]\n",
    "# Computing averages from sums\n",
    "for lag in tlags_1:\n",
    "    col = column + '_splag_1_' + str(lag)\n",
    "    df_pgm_historical_values[col] = df_pgm_historical_values[col]\n",
    "for lag in tlags_2:\n",
    "    col = column + '_splag_2_' + str(lag)\n",
    "    df_pgm_historical_values[col] = df_pgm_historical_values[col]\n",
    "\n",
    "\n",
    "\n",
    "df_pgm_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_historical_values_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating predictions for test partition\n",
    "number_of_lags_inner = 24\n",
    "number_of_lags_1 = 12\n",
    "number_of_lags_2 = 6\n",
    "maxstep = 14\n",
    "df_list_bystep = []\n",
    "for step in range(3,maxstep+1):\n",
    "    lags=range(step,number_of_lags_inner+step)\n",
    "    draw = 1\n",
    "#    print('step:',step,'lag:',lag, 'draw:',draw)\n",
    "    df_list = []\n",
    "    for lag in lags:\n",
    "        for coltype in [('ged_sb_best_sum_nokgi_',number_of_lags_inner),('ged_sb_best_sum_nokgi_splag_1_',number_of_lags_1),('ged_sb_best_sum_nokgi_splag_2_',number_of_lags_2)]:\n",
    "            number_of_repetitions = coltype[1]+step-lag\n",
    "            for repetition in range(1,number_of_repetitions+1):\n",
    "                if lag <= coltype[1] + step:\n",
    "                    lagged_col = coltype[0] + str(lag)\n",
    "#                    print('draw:',draw, 'step:', step, 'lag:',lag,'repetition:', repetition, 'colname:', lagged_col)\n",
    "                    df = pd.DataFrame(df_pgm_historical_values[lagged_col].copy())\n",
    "                    df.reset_index(inplace=True)\n",
    "                    df['prediction'] = df[lagged_col].astype('int32')\n",
    "                    df.drop(columns=[lagged_col], inplace=True)\n",
    "                    df['step'] = step\n",
    "                    df['draw'] = draw\n",
    "                    df.set_index(['month_id', 'priogrid_gid', 'step','draw'], inplace=True)\n",
    "                    df_list.append(df)\n",
    "                    draw = draw + 1\n",
    "    print('Concatenating', draw-1, 'repetitions for step', step)\n",
    "    df_pgm_predictions_lag = pd.concat(df_list)\n",
    "    df_list_bystep.append(df_pgm_predictions_lag)\n",
    "    \n",
    "#df_pgm_predictions_historical_values = pd.concat(df_list_bystep) \n",
    "#df_pgm_predictions_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff56a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_bystep[0].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ec044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating step-level dataframes\n",
    "single_file = False\n",
    "\n",
    "if single_file:\n",
    "    df_pgm_predictions_historical_values = df_list_bystep[0]\n",
    "    list_item = 1\n",
    "    for step in range(3+1,maxstep+1):\n",
    "        print('adding data for step', step)\n",
    "        df_pgm_predictions_historical_values = pd.concat([df_pgm_predictions_historical_values,df_list_bystep[list_item]])\n",
    "        list_item += 1\n",
    "\n",
    "    df_pgm_predictions_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccedd48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with actuals\n",
    "df_actuals_pgm = pd.DataFrame(df_pgm_historical_values_0['ged_sb'])\n",
    "print(df_actuals_pgm.head())\n",
    "print(df_actuals_pgm.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_actuals.parquet'\n",
    "df_actuals_pgm.to_parquet(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5055daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate across draws/samples to extract means, standard deviations, and category probabilities\n",
    "# export to parquet step by step\n",
    "step = 3\n",
    "for df in df_list_bystep:\n",
    "    print(step)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_historical_values_step_' + str(step) + '.parquet'\n",
    "    df.to_parquet(filename)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_historical_values_step_' + str(step) + '_aggregated.parquet'\n",
    "    df_aggregated = aggregate_and_categorize(df,'pgm')\n",
    "    df_aggregated.to_parquet(filename)\n",
    "\n",
    "    print(df_aggregated.describe())\n",
    "    print(df_aggregated.mean())\n",
    "        \n",
    "    step = step+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d69f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_historical_values.parquet'\n",
    "df_from_file = pd.read_parquet(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_historical_values_step_3.parquet'\n",
    "df_from_file = pd.read_parquet(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74afc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
