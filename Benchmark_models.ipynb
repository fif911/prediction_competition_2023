{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97aebc4f",
   "metadata": {},
   "source": [
    "# Benchmark model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ba263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import os\n",
    "\n",
    "\n",
    "# Views 3\n",
    "import views_runs\n",
    "from viewser.operations import fetch\n",
    "from views_forecasts.extensions import *\n",
    "from viewser import Queryset, Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common parameters:\n",
    "\n",
    "dev_id = 'Fatalities002'\n",
    "run_id = 'Fatalities002'\n",
    "EndOfHistory = 508\n",
    "level = 'cm'\n",
    "get_future = False\n",
    "\n",
    "username = os.getlogin()\n",
    "\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "\n",
    "fi_steps = [1,3,6,12,36]\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,396),\"predict\":(397,444)}\n",
    "test_partitioner_dict = {\"train\":(121,444),\"predict\":(445,492)}\n",
    "future_partitioner_dict = {\"train\":(121,492),\"predict\":(493,504)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = f'/Users/{username}/Dropbox (ViEWS)/ViEWS/'\n",
    "overleafpath = f'/Users/{username}/Dropbox (ViEWS)/Apps/Overleaf/ViEWS predicting fatalities/Tables/'\n",
    "\n",
    "\n",
    "\n",
    "print('Dropbox path set to',Mydropbox)\n",
    "print('Overleaf path set to',overleafpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a787408",
   "metadata": {},
   "source": [
    "## cm level"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af8bd551",
   "metadata": {},
   "source": [
    "### Based on constituent models\n",
    "\n",
    "Short version, 22 models: \n",
    "1 \"draw\"\n",
    "from each of 22 constituent models\n",
    "\n",
    "Long version, 440 models:\n",
    "20 \"draws\" from each of 22 constituent models, using predictions for adjacent steps (from s-4 to s+6). Some duplications to weight the most proximate steps more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989b764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fatalities002 stuff - contains the list of the current fatalities002 ensemble models\n",
    "\n",
    "from ModelDefinitions import DefineEnsembleModels\n",
    "\n",
    "ModelList = DefineEnsembleModels(level)\n",
    "    \n",
    "i = 0\n",
    "for model in ModelList:\n",
    "    print(i, model['modelname'], model['data_train'])\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656cc859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "\n",
    "ModelList = RetrieveStoredPredictions(ModelList, steps, EndOfHistory, dev_id, level, get_future)\n",
    "\n",
    "ModelList = CalibratePredictions(ModelList, EndOfHistory, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3358741",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelList[0]['predictions_test_df']\n",
    "ModelList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a00e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with actuals\n",
    "df_actuals = pd.DataFrame(ModelList[0]['predictions_test_df']['ln_ged_sb_dep'])\n",
    "print(df_actuals.head())\n",
    "print(df_actuals.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcb7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_df(df, draw):\n",
    "    ''' Drops steps we will not need in the benchmark model. \n",
    "    Another round of drops are done below '''\n",
    "    steps_to_drop = ['ln_ged_sb_dep','step_pred_21','step_pred_22','step_pred_23','step_pred_24',\n",
    "                     'step_pred_25','step_pred_26','step_pred_27','step_pred_28','step_pred_29','step_pred_30',\n",
    "                     'step_pred_31','step_pred_32','step_pred_33','step_pred_34','step_pred_35','step_pred_36',]\n",
    "    df = df.drop(steps_to_drop,axis=1)\n",
    "    df.reset_index(inplace=True)\n",
    "    df['draw'] = draw\n",
    "    df_long = pd.wide_to_long(df, 'step_pred_', i = ['month_id', 'country_id', 'draw'], j = 'step')\n",
    "    return(df_long)\n",
    "    \n",
    "model_draw = 0\n",
    "df = ModelList[model_draw]['predictions_test_df'].copy()\n",
    "df_cm_results_long = reshape_df(df,model_draw)\n",
    "print('Starting with model/draw',model_draw, model['modelname'])\n",
    "print(df_cm_results_long.describe())\n",
    "\n",
    "\n",
    "for model in ModelList[1:]:\n",
    "    model_draw += 1\n",
    "    print('Appending model/draw',model_draw, model['modelname'])\n",
    "    df = ModelList[model_draw]['predictions_test_df'].copy()\n",
    "    df_reshaped = reshape_df(df,model_draw)\n",
    "    df_cm_results_long = pd.concat([df_cm_results_long ,df_reshaped], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe118d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_results_long['prediction'] = np.round_(np.expm1(df_cm_results_long['step_pred_'])).astype('int32')\n",
    "df_cm_results_long.drop(columns=['step_pred_'], inplace=True)\n",
    "# Results file in long format\n",
    "print(df_cm_results_long.describe())\n",
    "print(df_cm_results_long.tail())\n",
    "\n",
    "print(df_cm_results_long.loc[492].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982bbf85",
   "metadata": {},
   "outputs": [],
   "source": [
    "84040/(22*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf25dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extending by copying adjacent steps\n",
    "\n",
    "df_cm_results_extended=df_cm_results_long.copy()\n",
    "print(df_cm_results_extended.describe())\n",
    "print(df_cm_results_extended.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1871a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_final_extended = df_cm_results_extended.copy()\n",
    "\n",
    "def make_dfcopy(df_in, step, shifted_step, repetition):\n",
    "    ''' Makes a 'copy' of the df with a shifted step '''\n",
    "#    print(step, shifted_step, repetition)\n",
    "    df = pd.DataFrame(df_in[df_in.index.get_level_values('step').isin([shifted_step])]).copy()\n",
    "    df.reset_index(inplace = True)\n",
    "    df['step'].replace(shifted_step, step, inplace = True)\n",
    "#    print(df.describe())\n",
    "    df['draw'] = (df['draw'] + len(ModelList) * repetition)\n",
    "#    print(df.describe())\n",
    "    df.set_index(['month_id', 'country_id','draw', 'step'], inplace=True)\n",
    "    return(df)\n",
    "    \n",
    "\n",
    "for step in range(3,14+1):     \n",
    "#    print(80*'*')\n",
    "    print('Step', step, '-- Original dataframe for step', step, 'is:')\n",
    "    df = pd.DataFrame(df_cm_results_extended[df_cm_results_extended.index.get_level_values('step').isin([step])])\n",
    "#    print(df.head(3))\n",
    "    repetition = 1\n",
    "    for shift in [(-4,1),(-3,1),(-2,2),(-1,3),(0,2),(1,3),(2,2),(3,2),(4,1),(5,1),(6,1)]:\n",
    "        for copy in range(1,shift[1]+1):\n",
    "            shifted_step = step+shift[0]\n",
    "            if shifted_step < 1:\n",
    "                shifted_step = step\n",
    "            step_list = [shifted_step]\n",
    "            df = make_dfcopy(df_in = df_cm_results_extended,step = step, shifted_step = shifted_step, repetition = repetition)\n",
    "            repetition += 1\n",
    "            df_cm_final_extended = pd.concat([df_cm_final_extended, df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9996a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(make_dfcopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdacaf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_results_long.loc[492].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722f21fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_final_extended.loc[492].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b822a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_final_extended.loc[492].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ea11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning the original down to steps 3-14\n",
    "steps_to_keep = range(3,15)\n",
    "\n",
    "df_cm_results_long_pruned = df_cm_results_long[df_cm_results_long.index.get_level_values('step').isin(steps_to_keep)]\n",
    "df_cm_results_long_pruned.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d92db",
   "metadata": {},
   "source": [
    "### cm last historical values benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c89361",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = (Queryset(\"benchmark_cm\", \"country_month\")\n",
    "\n",
    "   # target variable\n",
    "   .with_column(Column(\"ged_sb\", from_table=\"ged2_cm\", from_column=\"ged_sb_best_sum_nokgi\")\n",
    "                .transform.missing.fill()\n",
    "                .transform.missing.replace_na()\n",
    "                )\n",
    "\n",
    "\n",
    "   .with_theme(\"benchmark\")\n",
    "   .describe(\"\"\"Data for empirical benchmark model, cm level\n",
    "\n",
    "\n",
    "            \"\"\")\n",
    "   )\n",
    "\n",
    "#queryset = Queryset(\"name\", \"loa\") # if not already defined\n",
    "column = \"ged_sb_best_sum_nokgi\"\n",
    "table = \"ged2_cm\"\n",
    "lags=range(1,49)\n",
    "for lag in lags: \n",
    "    qs = qs.with_column(Column(column+'_' + str(lag), from_table = table, from_column=column)\n",
    "                        .transform.missing.replace_na()\n",
    "                        .transform.temporal.tlag(lag)\n",
    "                       )\n",
    "df_cm_historical_values = qs.publish().fetch()\n",
    "df_cm_historical_values = df_cm_historical_values.loc[445:492]\n",
    "\n",
    "df_cm_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating predictions for test partition\n",
    "number_of_lags = 45\n",
    "lags=range(1,number_of_lags)\n",
    "maxstep = 14\n",
    "df_list_bystep = []\n",
    "for step in range(3,maxstep+1):\n",
    "    print('step:',step,'lag:',lag, 'draw:',draw)\n",
    "    draw = 1\n",
    "    df_list = []\n",
    "    for lag in lags:\n",
    "        number_of_repetitions = number_of_lags+1-lag\n",
    "#        print('lag:',lag,'repetitions:',number_of_repetitions)\n",
    "#        print('step:',step,'lag:',lag, 'draw:',draw)\n",
    "        for repetition in range(1,number_of_repetitions):\n",
    "            lagged_col = 'ged_sb_best_sum_nokgi_' + str(lag)\n",
    "            df = pd.DataFrame(df_cm_historical_values[lagged_col].copy())\n",
    "            df.reset_index(inplace=True)\n",
    "            df['prediction'] = df[lagged_col]\n",
    "#            print(df.head())\n",
    "            df.drop(columns=[lagged_col], inplace=True)\n",
    "            df['step'] = step\n",
    "            df['draw'] = draw\n",
    "            df.set_index(['month_id', 'country_id','draw', 'step'], inplace=True)\n",
    "            df_list.append(df)\n",
    "#            if draw == 1 and step == 1:\n",
    "#                df_cm_predictions_historical_values = df.copy()\n",
    "#            else:\n",
    "#                df_cm_predictions_historical_values = pd.concat([df_cm_predictions_historical_values,df])\n",
    "            draw = draw + 1\n",
    "    df_cm_predictions_lag = pd.concat(df_list)\n",
    "    df_list_bystep.append(df_cm_predictions_lag)\n",
    "    \n",
    "df_cm_predictions_historical_values = pd.concat(df_list_bystep) \n",
    "\n",
    "df_cm_predictions_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8a4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_predictions_historical_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947356fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_actuals.csv'\n",
    "df_actuals.to_csv(filename)\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_ensemble_22.parquet'\n",
    "df_cm_results_long_pruned.to_parquet(filename)\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_ensemble_440.parquet'\n",
    "df_cm_final_extended.to_parquet(filename)\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_historical_values.parquet'\n",
    "df_cm_predictions_historical_values.to_parquet(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51884343",
   "metadata": {},
   "source": [
    "# pgm benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7c4314",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = (Queryset(\"benchmark_pgm\", \"priogrid_month\")\n",
    "\n",
    "   # target variable\n",
    "   .with_column(Column(\"ged_sb\", from_table=\"ged2_pgm\", from_column=\"ged_sb_best_sum_nokgi\")\n",
    "                .transform.missing.fill()\n",
    "                .transform.missing.replace_na()\n",
    "                )\n",
    "\n",
    "    .with_column(Column(\"ged_os\", from_table=\"ged2_pgm\", from_column=\"ged_os_best_sum_nokgi\")\n",
    "                 .transform.missing.fill()\n",
    "                 .transform.missing.replace_na()\n",
    "                 )\n",
    "\n",
    "    .with_column(Column(\"ged_ns\", from_table=\"ged2_pgm\", from_column=\"ged_ns_best_sum_nokgi\")\n",
    "                 .transform.missing.fill()\n",
    "                 .transform.missing.replace_na()\n",
    "                 )\n",
    "\n",
    "   # Spatial lag\n",
    "   .with_column(Column(\"splag_1_1_sb_1\", from_table=\"ged2_pgm\", from_column=\"ged_sb_best_sum_nokgi\")\n",
    "                .transform.missing.replace_na()\n",
    "                .transform.bool.gte(1)\n",
    "                .transform.temporal.time_since()\n",
    "                .transform.temporal.decay(24)\n",
    "                .transform.spatial.lag(1, 1, 0, 0)\n",
    "                .transform.missing.replace_na()\n",
    "                )\n",
    "   # timelags 1-12 of target variable\n",
    "   .with_column(Column(\"ged_sb_tlag_1\", from_table=\"ged2_pgm\",\n",
    "                       from_column=\"ged_sb_best_sum_nokgi\")\n",
    "                .transform.missing.fill()\n",
    "                .transform.temporal.tlag(1)\n",
    "                .transform.missing.fill()\n",
    "                )\n",
    "\n",
    "   .with_theme(\"benchmark\")\n",
    "   .describe(\"\"\"Data for empirical benchmark model, pgm level\n",
    "\n",
    "\n",
    "            \"\"\")\n",
    "   )\n",
    "\n",
    "data = qs.publish().fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
