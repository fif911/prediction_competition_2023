{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-15T10:57:25.358724Z",
     "start_time": "2024-04-15T10:57:24.780411Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "cm_features = pd.read_csv('/Users/zakotianskyi/PycharmProjects/prediction_competition_2023/data/cm_features_v0.6.csv')\n",
    "cm_features.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62501 entries, 0 to 62500\n",
      "Columns: 148 entries, month_id to ged_sb_y_18\n",
      "dtypes: float64(120), int64(25), object(3)\n",
      "memory usage: 70.6+ MB\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "TARGET_COLUMNS = ['a_ged_sb_y_18', 'b_ged_sb_y_18']\n",
    "\n",
    "# Explicitly list columns to be dropped before scaling\n",
    "columns_to_drop = ['month_id',\n",
    "                   'date',\n",
    "                   'country_id',\n",
    "                   'country_id',\n",
    "                   'ccode',\n",
    "                   'country_name',\n",
    "                   '',\n",
    "                   ]\n",
    "\n",
    "# drop categorical columns\n",
    "categorical = ['has_active_riv', 'principal',\n",
    "               'asymmetric_principal',\n",
    "               'positional',\n",
    "               'spatial',\n",
    "               'ideological',\n",
    "               'interventionary', 'a_is_major', 'b_is_major']\n",
    "\n",
    "columns_to_drop.extend(categorical)\n",
    "columns_to_drop.extend(['a_country_name', 'b_country_name'])\n",
    "\n",
    "# Also, drop one-hot encoded country identifiers if they are already in the dataframe\n",
    "columns_to_drop.extend(dyad_df.filter(regex='^country_id_a_').columns.tolist())\n",
    "columns_to_drop.extend(dyad_df.filter(regex='^country_id_b_').columns.tolist())\n",
    "\n",
    "columns_to_drop.extend(dyad_df.filter(regex='decay|splag|vdem').columns.tolist())\n",
    "\n",
    "# Determine numeric columns by excluding the ones to drop from the dataframe\n",
    "numeric_columns = dyad_df.drop(columns=columns_to_drop).columns.tolist()\n",
    "list(numeric_columns)"
   ],
   "id": "6378b8b1a8b2e0b9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "PLOT_FIGURES = False\n",
    "\n",
    "\n",
    "def plot_column_distributions(dataframe, columns, folder='plots', img_size=(4, 3)):\n",
    "    \"\"\"\n",
    "    Plot and save histograms for specified columns in a dataframe.\n",
    "\n",
    "    Parameters:\n",
    "    - dataframe: pandas DataFrame containing the data.\n",
    "    - columns: List of column names to plot.\n",
    "    - folder: String specifying the directory to save the plots.\n",
    "    - img_size: Tuple specifying the size of the images.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    # remove dir if exists\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    skewed_columns = []\n",
    "    other_columns = []\n",
    "\n",
    "    for col in columns:\n",
    "        if col.startswith('b_'):  # skip b_ columns\n",
    "            continue\n",
    "\n",
    "        # Check if the column exists in the dataframe to avoid KeyError\n",
    "        if col in dataframe.columns:\n",
    "            col_data = dataframe[col].dropna()\n",
    "\n",
    "            # Log the minimum and maximum values of the column. Round to 2 decimal places.\n",
    "            min_val = round(col_data.min(), 2)\n",
    "            max_val = round(col_data.max(), 2)\n",
    "            skewness = round(col_data.skew(), 2)\n",
    "\n",
    "            cols = [col]\n",
    "            if col.startswith('a_'):\n",
    "                cols = [col, 'b_' + col[2:]]\n",
    "\n",
    "            if skewness > 1:\n",
    "                skewed_columns.extend(cols)\n",
    "            else:\n",
    "                other_columns.extend(cols)\n",
    "\n",
    "            print(f\"Column: {col} - Min: {min_val}, Max: {max_val} - Skew: {skewness}\")\n",
    "            if PLOT_FIGURES:\n",
    "                plt.figure(figsize=img_size)\n",
    "                col_data.hist(bins=12, alpha=0.75)\n",
    "                plt.title(f\"{col} - Min: {min_val}, Max: {max_val} - Skew: {skewness}\")\n",
    "                plt.xlabel('Value')\n",
    "                plt.ylabel('Frequency')\n",
    "\n",
    "                # Save the plot\n",
    "                plt.savefig(f\"{folder}/{col}.png\", format='png', dpi=100)\n",
    "                plt.close()  # Close the figure to free memory\n",
    "        else:\n",
    "            print(f\"Column {col} not found in dataframe.\")\n",
    "\n",
    "    return skewed_columns, other_columns\n",
    "\n",
    "\n",
    "# Usage:\n",
    "skewed_cols, other_columns = plot_column_distributions(cm_features, numeric_columns)"
   ],
   "id": "97c79df8aad6201e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import joblib  # For saving scikit-learn models\n",
    "\n",
    "\n",
    "def fit_and_transform_data(train_df, test_df, skewed_cols, other_cols):\n",
    "    \"\"\"\n",
    "    Fits scalers to the train_df and transforms both train_df and test_df.\n",
    "    Saves the scalers for later use.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_df: pandas DataFrame, training data.\n",
    "    - test_df: pandas DataFrame, testing data.\n",
    "    - skewed_cols: List of column names that are heavily right-skewed.\n",
    "    - other_cols: List of column names that are not heavily right-skewed.\n",
    "    \n",
    "    Returns:\n",
    "    - train_df_scaled: Scaled training data.\n",
    "    - test_df_scaled: Scaled testing data.\n",
    "    \"\"\"\n",
    "    # Define the transformations for each group of features\n",
    "    transformers = [\n",
    "        ('quantile', QuantileTransformer(output_distribution='normal'), skewed_cols),\n",
    "        ('standard', StandardScaler(), other_cols)\n",
    "    ]\n",
    "\n",
    "    # Create a ColumnTransformer to apply the scaling\n",
    "    preprocessor = ColumnTransformer(transformers, remainder='passthrough')\n",
    "\n",
    "    # Fit and transform the training data\n",
    "    train_df_scaled = preprocessor.fit_transform(train_df)\n",
    "    train_df_scaled = pd.DataFrame(train_df_scaled, columns=train_df.columns, index=train_df.index)\n",
    "\n",
    "    # Transform the testing data using the fitted scalers from the training data\n",
    "    test_df_scaled = preprocessor.transform(test_df)\n",
    "    test_df_scaled = pd.DataFrame(test_df_scaled, columns=test_df.columns, index=test_df.index)\n",
    "\n",
    "    # Save the preprocessor model for inverse transform or further transformations\n",
    "    joblib.dump(preprocessor, 'data_scaler.joblib')\n",
    "\n",
    "    return train_df_scaled, test_df_scaled\n",
    "\n",
    "\n",
    "# Assuming you have the 'train_df' and 'test_df' DataFrames already loaded\n",
    "train_df_scaled, test_df_scaled = fit_and_transform_data(train_df, test_df, skewed_cols, other_columns)\n",
    "\n",
    "print(train_df_scaled.head())\n",
    "print(test_df_scaled.head())"
   ],
   "id": "644bc169360d245"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
