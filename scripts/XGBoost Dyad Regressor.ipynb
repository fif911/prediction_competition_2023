{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:02:40.930361Z",
     "start_time": "2024-03-25T09:02:13.546108Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 562495 entries, 5526414 to 6088908\n",
      "Columns: 263 entries, month_id to ratio_wdi_ms_mil_xpnd_zs\n",
      "dtypes: datetime64[ns](1), float64(255), int64(5), object(2)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "dyad_df = pd.read_parquet('data_dyad_monthly/dyad_df.parquet')\n",
    "# get only dyads from Jan 2016 to Jan 2019\n",
    "# to date\n",
    "dyad_df['date'] = pd.to_datetime(dyad_df['date'])\n",
    "dyad_df = dyad_df[\n",
    "    (dyad_df['date'] >= pd.Timestamp(year=2016, month=7, day=1)) &\n",
    "    (dyad_df['date'] <= pd.Timestamp(year=2019, month=1, day=1))]\n",
    "dyad_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "         month_id       date  country_id_a  country_id_b a_country_name  \\\n5526414       439 2016-07-01             1             2         Guyana   \n5526415       439 2016-07-01             1             3         Guyana   \n5526416       439 2016-07-01             1             4         Guyana   \n5526417       439 2016-07-01             1             5         Guyana   \n5526418       439 2016-07-01             1             6         Guyana   \n...           ...        ...           ...           ...            ...   \n6088904       469 2019-01-01           243           245        Morocco   \n6088905       469 2019-01-01           243           246        Morocco   \n6088906       469 2019-01-01           244           245     Mauritania   \n6088907       469 2019-01-01           244           246     Mauritania   \n6088908       469 2019-01-01           245           246          Sudan   \n\n              b_country_name  a_gleditsch_ward  a_ged_sb  a_ged_ns  a_ged_os  \\\n5526414             Suriname               110       0.0       0.0       0.0   \n5526415  Trinidad and Tobago               110       0.0       0.0       0.0   \n5526416            Venezuela               110       0.0       0.0       0.0   \n5526417                Samoa               110       0.0       0.0       0.0   \n5526418                Tonga               110       0.0       0.0       0.0   \n...                      ...               ...       ...       ...       ...   \n6088904                Sudan               600       0.0       0.0       0.0   \n6088905          South Sudan               600       0.0       0.0       0.0   \n6088906                Sudan               435       0.0       0.0       0.0   \n6088907          South Sudan               435       0.0       0.0       0.0   \n6088908          South Sudan               625       5.0       0.0      17.0   \n\n         ...  b_renewable_internal_pcap_t48  b_renewable_pcap_t48  \\\n5526414  ...                  182911.620431         182911.620431   \n5526415  ...                    2855.402846           2855.402846   \n5526416  ...                   27417.474509          45128.141272   \n5526417  ...                       0.000000              0.000000   \n5526418  ...                       0.000000              0.000000   \n...      ...                            ...                   ...   \n6088904  ...                     102.819966            971.648680   \n6088905  ...                    2426.355899           4619.408346   \n6088906  ...                     102.819966            971.648680   \n6088907  ...                    2426.355899           4619.408346   \n6088908  ...                    2426.355899           4619.408346   \n\n         b_splag_1_decay_ged_sb_5  b_splag_1_decay_ged_os_5  \\\n5526414                  0.000006                  0.128716   \n5526415                  0.000000                  0.000000   \n5526416                  0.971538                  0.614482   \n5526417                  0.000000                  0.000000   \n5526418                  0.000000                  0.000000   \n...                           ...                       ...   \n6088904                  6.149093                  5.183314   \n6088905                  4.719313                  5.131790   \n6088906                  6.149093                  5.183314   \n6088907                  4.719313                  5.131790   \n6088908                  4.719313                  5.131790   \n\n         b_splag_1_decay_ged_ns_5  ratio_wdi_sp_pop_totl  ratio_ged_sb  \\\n5526414                  0.749157               1.312014      0.000000   \n5526415                  0.000000               0.517082      0.000000   \n5526416                  0.776997               0.024731      0.000000   \n5526417                  0.000000               3.708932      0.000000   \n5526418                  0.000000               7.114745      0.000000   \n...                           ...                    ...           ...   \n6088904                  4.848733               0.855436      0.000000   \n6088905                  5.177793               3.456121      0.000000   \n6088906                  4.848733               0.101686      0.000000   \n6088907                  5.177793               0.410830      0.000000   \n6088908                  5.177793               4.040186      0.131579   \n\n         ratio_wdi_sp_dyn_imrt_in  ratio_vdem_v2x_ex_military  \\\n5526414                  1.497268                    0.000000   \n5526415                  1.565714                    0.000000   \n5526416                  1.660606                    0.000000   \n5526417                  1.723270                    0.000000   \n5526418                  2.584906                    0.000000   \n...                           ...                         ...   \n6088904                  0.416667                    0.497006   \n6088905                  0.274295                    0.415000   \n6088906                  0.826190                    2.497006   \n6088907                  0.543887                    2.085000   \n6088908                  0.658307                    0.835000   \n\n         ratio_wdi_ms_mil_xpnd_zs  \n5526414                  4.957652  \n5526415                  2.305654  \n5526416                  4.957652  \n5526417                  4.957652  \n5526418                  4.957652  \n...                           ...  \n6088904                  0.992970  \n6088905                  1.067648  \n6088906                  1.062418  \n6088907                  1.142318  \n6088908                  1.075206  \n\n[562495 rows x 263 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>month_id</th>\n      <th>date</th>\n      <th>country_id_a</th>\n      <th>country_id_b</th>\n      <th>a_country_name</th>\n      <th>b_country_name</th>\n      <th>a_gleditsch_ward</th>\n      <th>a_ged_sb</th>\n      <th>a_ged_ns</th>\n      <th>a_ged_os</th>\n      <th>...</th>\n      <th>b_renewable_internal_pcap_t48</th>\n      <th>b_renewable_pcap_t48</th>\n      <th>b_splag_1_decay_ged_sb_5</th>\n      <th>b_splag_1_decay_ged_os_5</th>\n      <th>b_splag_1_decay_ged_ns_5</th>\n      <th>ratio_wdi_sp_pop_totl</th>\n      <th>ratio_ged_sb</th>\n      <th>ratio_wdi_sp_dyn_imrt_in</th>\n      <th>ratio_vdem_v2x_ex_military</th>\n      <th>ratio_wdi_ms_mil_xpnd_zs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>5526414</th>\n      <td>439</td>\n      <td>2016-07-01</td>\n      <td>1</td>\n      <td>2</td>\n      <td>Guyana</td>\n      <td>Suriname</td>\n      <td>110</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>182911.620431</td>\n      <td>182911.620431</td>\n      <td>0.000006</td>\n      <td>0.128716</td>\n      <td>0.749157</td>\n      <td>1.312014</td>\n      <td>0.000000</td>\n      <td>1.497268</td>\n      <td>0.000000</td>\n      <td>4.957652</td>\n    </tr>\n    <tr>\n      <th>5526415</th>\n      <td>439</td>\n      <td>2016-07-01</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Guyana</td>\n      <td>Trinidad and Tobago</td>\n      <td>110</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2855.402846</td>\n      <td>2855.402846</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.517082</td>\n      <td>0.000000</td>\n      <td>1.565714</td>\n      <td>0.000000</td>\n      <td>2.305654</td>\n    </tr>\n    <tr>\n      <th>5526416</th>\n      <td>439</td>\n      <td>2016-07-01</td>\n      <td>1</td>\n      <td>4</td>\n      <td>Guyana</td>\n      <td>Venezuela</td>\n      <td>110</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>27417.474509</td>\n      <td>45128.141272</td>\n      <td>0.971538</td>\n      <td>0.614482</td>\n      <td>0.776997</td>\n      <td>0.024731</td>\n      <td>0.000000</td>\n      <td>1.660606</td>\n      <td>0.000000</td>\n      <td>4.957652</td>\n    </tr>\n    <tr>\n      <th>5526417</th>\n      <td>439</td>\n      <td>2016-07-01</td>\n      <td>1</td>\n      <td>5</td>\n      <td>Guyana</td>\n      <td>Samoa</td>\n      <td>110</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.708932</td>\n      <td>0.000000</td>\n      <td>1.723270</td>\n      <td>0.000000</td>\n      <td>4.957652</td>\n    </tr>\n    <tr>\n      <th>5526418</th>\n      <td>439</td>\n      <td>2016-07-01</td>\n      <td>1</td>\n      <td>6</td>\n      <td>Guyana</td>\n      <td>Tonga</td>\n      <td>110</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.114745</td>\n      <td>0.000000</td>\n      <td>2.584906</td>\n      <td>0.000000</td>\n      <td>4.957652</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6088904</th>\n      <td>469</td>\n      <td>2019-01-01</td>\n      <td>243</td>\n      <td>245</td>\n      <td>Morocco</td>\n      <td>Sudan</td>\n      <td>600</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>102.819966</td>\n      <td>971.648680</td>\n      <td>6.149093</td>\n      <td>5.183314</td>\n      <td>4.848733</td>\n      <td>0.855436</td>\n      <td>0.000000</td>\n      <td>0.416667</td>\n      <td>0.497006</td>\n      <td>0.992970</td>\n    </tr>\n    <tr>\n      <th>6088905</th>\n      <td>469</td>\n      <td>2019-01-01</td>\n      <td>243</td>\n      <td>246</td>\n      <td>Morocco</td>\n      <td>South Sudan</td>\n      <td>600</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2426.355899</td>\n      <td>4619.408346</td>\n      <td>4.719313</td>\n      <td>5.131790</td>\n      <td>5.177793</td>\n      <td>3.456121</td>\n      <td>0.000000</td>\n      <td>0.274295</td>\n      <td>0.415000</td>\n      <td>1.067648</td>\n    </tr>\n    <tr>\n      <th>6088906</th>\n      <td>469</td>\n      <td>2019-01-01</td>\n      <td>244</td>\n      <td>245</td>\n      <td>Mauritania</td>\n      <td>Sudan</td>\n      <td>435</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>102.819966</td>\n      <td>971.648680</td>\n      <td>6.149093</td>\n      <td>5.183314</td>\n      <td>4.848733</td>\n      <td>0.101686</td>\n      <td>0.000000</td>\n      <td>0.826190</td>\n      <td>2.497006</td>\n      <td>1.062418</td>\n    </tr>\n    <tr>\n      <th>6088907</th>\n      <td>469</td>\n      <td>2019-01-01</td>\n      <td>244</td>\n      <td>246</td>\n      <td>Mauritania</td>\n      <td>South Sudan</td>\n      <td>435</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>2426.355899</td>\n      <td>4619.408346</td>\n      <td>4.719313</td>\n      <td>5.131790</td>\n      <td>5.177793</td>\n      <td>0.410830</td>\n      <td>0.000000</td>\n      <td>0.543887</td>\n      <td>2.085000</td>\n      <td>1.142318</td>\n    </tr>\n    <tr>\n      <th>6088908</th>\n      <td>469</td>\n      <td>2019-01-01</td>\n      <td>245</td>\n      <td>246</td>\n      <td>Sudan</td>\n      <td>South Sudan</td>\n      <td>625</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>17.0</td>\n      <td>...</td>\n      <td>2426.355899</td>\n      <td>4619.408346</td>\n      <td>4.719313</td>\n      <td>5.131790</td>\n      <td>5.177793</td>\n      <td>4.040186</td>\n      <td>0.131579</td>\n      <td>0.658307</td>\n      <td>0.835000</td>\n      <td>1.075206</td>\n    </tr>\n  </tbody>\n</table>\n<p>562495 rows Ã— 263 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dyad_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:02:56.635189Z",
     "start_time": "2024-03-25T09:02:56.544517Z"
    }
   },
   "id": "6ec5556f63852aa6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from utilities import views_month_id_to_date\n",
    "\n",
    "# load benchmark model\n",
    "prediction_year = 2019\n",
    "model_names = {\n",
    "    \"bootstrap\": \"bm_cm_bootstrap_expanded_\",\n",
    "    \"poisson\": \"bm_cm_last_historical_poisson_expanded_\",\n",
    "}\n",
    "benchmark_model = pd.read_parquet(f'Benchmarks/{model_names[\"bootstrap\"]}{prediction_year}.parquet')\n",
    "# there is 20 draws per each country per each month. Get the mean of the draws\n",
    "benchmark_model = benchmark_model.groupby(['month_id', 'country_id']).mean().reset_index()\n",
    "# add date column\n",
    "benchmark_model['date'] = views_month_id_to_date(benchmark_model['month_id'])\n",
    "benchmark_model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a10c974bc9deda"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "# countries_encoded = encoder.fit_transform(dyad_df[['country_id_a', 'country_id_b']])\n",
    "# countries_encoded = encoder.transform(dyad_df[['country_id_a', 'country_id_b']])\n",
    "# countries_encoded = pd.DataFrame(countries_encoded, columns=encoder.get_feature_names(['country_id_a', 'country_id_b']))\n",
    "# countries_encoded\n",
    "# trasnform country_id_a and country_id_b to one hot encoding and remove the original columns\n",
    "# country_a_and_b_ids = dyad_df[dyad_df['country_id_a'], dyad_df['country_id_b']]\n",
    "\n",
    "\n",
    "# country_a_and_b_ids = dyad_df[['country_id_a', 'country_id_b']]\n",
    "# dyad_df = pd.get_dummies(dyad_df, columns=['country_id_a', 'country_id_b'], drop_first=False, dtype=int)\n",
    "# # merge back country_id_a and country_id_b\n",
    "# dyad_df = pd.concat([dyad_df, country_a_and_b_ids], axis=1)\n",
    "# dyad_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ab765c634db1b38"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "fca2873bc09264bc"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "cut_year = prediction_year - 2  # 2016\n",
    "\n",
    "features_to_oct = pd.Timestamp(year=cut_year, month=10, day=1)  # 2016-Oct-01\n",
    "\n",
    "# Splitting the dataset\n",
    "train_df = dyad_df[dyad_df['date'] <= features_to_oct]\n",
    "# test_df is one year from Oct 2016 to Oct 2017\n",
    "test_df = dyad_df[\n",
    "    (dyad_df['date'] >= pd.Timestamp(year=prediction_year - 2, month=10, day=1)) &  # oct 2016 predicts Jan 2018\n",
    "    (dyad_df['date'] < pd.Timestamp(year=prediction_year - 1, month=10, day=1))]  # oct 2017 predicts Jan 2019\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-24T21:58:43.575730Z",
     "start_time": "2024-03-24T21:58:41.065718Z"
    }
   },
   "id": "73ef0daee7c3fe05"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Explicitly list columns to be dropped before scaling\n",
    "columns_to_drop = ['country_id_a', 'country_id_b', 'date', 'a_ged_sb', 'b_ged_sb', 'a_gleditsch_ward',\n",
    "                   'b_gleditsch_ward', 'a_country_name', 'b_country_name']\n",
    "columns_to_re_add = ['a_ged_sb', 'b_ged_sb']\n",
    "\n",
    "# Also, drop one-hot encoded country identifiers if they are already in the dataframe\n",
    "columns_to_re_add.extend(dyad_df.filter(regex='^country_id_a_').columns.tolist())\n",
    "columns_to_re_add.extend(dyad_df.filter(regex='^country_id_b_').columns.tolist())\n",
    "\n",
    "# Determine numeric columns by excluding the ones to drop from the dataframe\n",
    "numeric_columns = dyad_df.drop(columns=columns_to_drop).drop(columns_to_re_add).columns.tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5e86dc891b4f2bdd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "TARGET_COLUMNS = ['a_ged_sb', 'b_ged_sb']\n",
    "\n",
    "# Initialize the scaler using only the training data\n",
    "scaler = StandardScaler().fit(train_df.drop(TARGET_COLUMNS, axis=1))\n",
    "\n",
    "# Apply the transformations to both the training and test sets\n",
    "train_df_scaled = scaler.transform(train_df.drop(TARGET_COLUMNS, axis=1))\n",
    "test_df_scaled = scaler.transform(test_df.drop(TARGET_COLUMNS, axis=1))\n",
    "\n",
    "# Reconstruct the dataframes with normalized features and the targets\n",
    "train_df = pd.DataFrame(train_df_scaled, columns=train_df.columns.drop(TARGET_COLUMNS))\n",
    "train_df[TARGET_COLUMNS] = train_df[TARGET_COLUMNS]\n",
    "\n",
    "test_df = pd.DataFrame(test_df_scaled, columns=test_df.columns.drop(TARGET_COLUMNS))\n",
    "test_df[TARGET_COLUMNS] = test_df[TARGET_COLUMNS]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "614f224d36c21b0e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "class CountryDyadDataset(Dataset):\n",
    "    def __init__(self, dataframe, feature_columns, target_columns=None):\n",
    "        if target_columns is None:\n",
    "            target_columns = TARGET_COLUMNS\n",
    "        self.features = torch.tensor(dataframe[feature_columns].values, dtype=torch.float)\n",
    "        self.targets = torch.tensor(dataframe[target_columns].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be862a6da485d3df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c2382ad0fa6df8a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Update feature_columns to exclude only the targets and other non-feature columns, based on the final dataframe\n",
    "feature_columns = [col for col in train_df_final.columns if col not in ['a_ged_sb', 'b_ged_sb']]\n",
    "\n",
    "train_dataset = CountryDyadDataset(train_df_final, feature_columns)\n",
    "test_dataset = CountryDyadDataset(test_df_final, feature_columns)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bfcc39512b31e80"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CountryDyadDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.dataframe = dataframe\n",
    "        self.features = torch.tensor(self.dataframe.drop(['a_ged_sb', 'b_ged_sb'], axis=1).values, dtype=torch.float)\n",
    "        self.targets = torch.tensor(self.dataframe[['a_ged_sb', 'b_ged_sb']].values, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "\n",
    "# Creating dataset object\n",
    "data_set = Data()\n",
    "\n",
    "\n",
    "# Creating a custom Multiple Linear Regression Model\n",
    "class MultipleLinearRegression(torch.nn.Module):\n",
    "    # Constructor\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MultipleLinearRegression, self).__init__()\n",
    "        self.linear = torch.nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    # Prediction\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "# Creating the model object\n",
    "MLR_model = MultipleLinearRegression(2, 2)\n",
    "print(\"The parameters: \", list(MLR_model.parameters()))\n",
    "\n",
    "# defining the model optimizer\n",
    "optimizer = torch.optim.SGD(MLR_model.parameters(), lr=0.1)\n",
    "# defining the loss criterion\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Creating the dataloader\n",
    "train_loader = DataLoader(dataset=data_set, batch_size=64)\n",
    "\n",
    "# Train the model\n",
    "losses = []\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    for x, y in train_loader:\n",
    "        y_pred = MLR_model(x)\n",
    "        loss = criterion(y_pred, y)\n",
    "        losses.append(loss.item())\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"epoch = {epoch}, loss = {loss}\")\n",
    "print(\"Done training!\")\n",
    "\n",
    "# Plot the losses\n",
    "plt.plot(losses)\n",
    "plt.xlabel(\"no. of iterations\")\n",
    "plt.ylabel(\"total loss\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ac877b31fe2dcb8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
