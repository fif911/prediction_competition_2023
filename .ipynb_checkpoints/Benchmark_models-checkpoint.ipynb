{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97aebc4f",
   "metadata": {},
   "source": [
    "# Benchmark model generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4e7ba263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cbook as cbook\n",
    "import os\n",
    "from functools import partial\n",
    "\n",
    "# Views 3\n",
    "import views_runs\n",
    "from viewser.operations import fetch\n",
    "from views_forecasts.extensions import *\n",
    "from viewser import Queryset, Column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fdc723d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropbox path set to /Users/jim/Dropbox (ViEWS)/ViEWS/\n",
      "Overleaf path set to /Users/jim/Dropbox (ViEWS)/Apps/Overleaf/Prediction competition 2023/\n"
     ]
    }
   ],
   "source": [
    "# Common parameters:\n",
    "\n",
    "dev_id = 'Fatalities002'\n",
    "run_id = 'Fatalities002'\n",
    "EndOfHistory = 508\n",
    "get_future = False\n",
    "\n",
    "username = os.getlogin()\n",
    "\n",
    "steps = [*range(1, 36+1, 1)] # Which steps to train and predict for\n",
    "\n",
    "fi_steps = [1,3,6,12,36]\n",
    "# Specifying partitions\n",
    "\n",
    "calib_partitioner_dict = {\"train\":(121,396),\"predict\":(397,456)}\n",
    "test_partitioner_dict = {\"train\":(121,444),\"predict\":(457,504)}\n",
    "future_partitioner_dict = {\"train\":(121,492),\"predict\":(505,512)}\n",
    "calib_partitioner =  views_runs.DataPartitioner({\"calib\":calib_partitioner_dict})\n",
    "test_partitioner =  views_runs.DataPartitioner({\"test\":test_partitioner_dict})\n",
    "future_partitioner =  views_runs.DataPartitioner({\"future\":future_partitioner_dict})\n",
    "\n",
    "Mydropbox = f'/Users/{username}/Dropbox (ViEWS)/ViEWS/'\n",
    "overleafpath = f'/Users/{username}/Dropbox (ViEWS)/Apps/Overleaf/Prediction competition 2023/'\n",
    "\n",
    "\n",
    "print('Dropbox path set to',Mydropbox)\n",
    "print('Overleaf path set to',overleafpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1983d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ln_ged_sb_dep', 'step_pred_3', 'step_pred_4', 'step_pred_5', 'step_pred_6', 'step_pred_7', 'step_pred_8', 'step_pred_9', 'step_pred_10', 'step_pred_11', 'step_pred_12', 'step_pred_13', 'step_pred_14']\n"
     ]
    }
   ],
   "source": [
    "# Benchmark model parameters\n",
    "filepath = Mydropbox + 'Prediction_competition_2023/'\n",
    "\n",
    "year_list = [2018, 2019, 2020, 2021]\n",
    "draws_cm = 1000\n",
    "draws_pgm = 100\n",
    "\n",
    "steps = [3,4,5,6,7,8,9,10,11,12,13,14]\n",
    "stepcols = ['ln_ged_sb_dep']\n",
    "for step in steps:\n",
    "    stepcols.append('step_pred_' + str(step))\n",
    "print(stepcols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598ae6c5",
   "metadata": {},
   "source": [
    "# Auxilliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "addc5b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sc predictions for a given calendar year\n",
    "\n",
    "def extract_sc_predictions(year,ss_predictions):\n",
    "    ''' Extract sc predictions'''\n",
    "    first_month = (year - 1980)*12 + 1\n",
    "    months=list(range(first_month,first_month+12))\n",
    "    df = ss_predictions.loc[months].copy()\n",
    "    df['prediction'] = 0\n",
    "    for month in range(1,12+1):\n",
    "        this_col = 'step_pred_' + str(month+2)\n",
    "        this_month = first_month + month - 1\n",
    "#        print(month, this_col, this_month)\n",
    "        df_temp = df.loc[this_month]\n",
    "#        print(df_temp[this_col].values)\n",
    "        df_temp['prediction'] = np.expm1(df_temp[this_col].values) \n",
    "        df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
    "    return pd.DataFrame(df['prediction'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ccffe5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand to n draws\n",
    "def expanded_predictions(sc_predictions, draws, level):\n",
    "    if level == 'cm':\n",
    "        level_index = ['month_id','country_id','draw']\n",
    "        unit_id = 'country_id'\n",
    "        counter_step = 100\n",
    "    elif level == 'pgm':\n",
    "        level_index = ['month_id','priogrid_id','draw']\n",
    "        unit_id = 'priogrid_id'\n",
    "        counter_step = 1000\n",
    "\n",
    "    rows = len(sc_predictions)\n",
    "\n",
    "    df = sc_predictions.copy().reset_index()\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    # Replace negative predictions with 0\n",
    "    df['prediction'] = np.where(df['prediction']<0, 0, df['prediction'])\n",
    "\n",
    "    sc_predictions_expanded = pd.DataFrame(index=sc_predictions.index)\n",
    "        \n",
    "    sc_predictions_expanded['draw'] = -1\n",
    "    sc_predictions_expanded.reset_index(inplace=True)\n",
    "    sc_predictions_expanded.set_index(level_index, inplace=True)\n",
    "    \n",
    "\n",
    "    for i in range(len(df)):\n",
    "        print(i,end=\" \")\n",
    "        df_r = df.iloc[i]\n",
    "        mu = df_r['prediction']\n",
    "        realization = pd.DataFrame(np.random.poisson(lam=mu, size=draws))\n",
    "        realization.rename(columns={0:'Poisson_sc'},inplace=True)\n",
    "        realization.index.rename('draw',inplace=True)\n",
    "        realization['month_id'] = df_r['month_id']\n",
    "        print(realization)\n",
    "        realization[unit_id] = df_r[unit_id]\n",
    "        realization.reset_index(inplace=True)\n",
    "        realization.set_index(level_index,inplace=True)\n",
    "        sc_predictions_expanded = pd.concat([sc_predictions_expanded,realization])\n",
    "    sc_predictions_expanded.drop(index=-1, level=2, inplace=True)\n",
    "    return sc_predictions_expanded\n",
    "\n",
    "def describe_expanded(df, df_expanded, month, country):\n",
    "    # Verify that the distribution is right\n",
    "    this_month = 457\n",
    "    this_country = 57\n",
    "    print(\"Mean and std of original predictions, all rows:\")\n",
    "    print(df.describe())\n",
    "    print(\"Mean and std of expanded predictions, all rows:\")\n",
    "    print(df_expanded.describe())\n",
    "    print(\"Mean and std of original predictions, one cm:\")\n",
    "    print(df.loc[this_month,this_country].describe())\n",
    "    print(\"Mean and std of expanded predictions, one cm:\")\n",
    "    print(df_expanded.loc[this_month,this_country].describe())\n",
    "    print(\"Variance:\",df_expanded.loc[this_month,this_country].var())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0b30314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_poisson_row(row: pd.DataFrame, ndraws:int = 100) -> pd.DataFrame:\n",
    "    \"\"\"Given a dataframe row, produce ndraws poisson draws from the prediction column in the row.\n",
    "    Attention, this is a row vectorized approach, should be used with apply.\n",
    "    :return an np array. Should be exploded for long df.\n",
    "    \"\"\"\n",
    "    row.prediction = 0 if row.prediction<=0 else row.prediction\n",
    "    return np.random.poisson(row.prediction, size=ndraws)\n",
    "\n",
    "function_with_draws = partial(sample_poisson_row, ndraws=1000)\n",
    "\n",
    "test_data = sc_predictions_ensemble[0].get('prediction_df')\n",
    "test_data['draws'] = test_data.apply(function_with_draws, axis=1)\n",
    "test_data.explode('draws')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a787408",
   "metadata": {},
   "source": [
    "## cm level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e753bec8",
   "metadata": {},
   "source": [
    "### Based on ensemble; expanded using a Poisson draw with mean=variance=\\hat{y}_{it}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3d09e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_46_cm_ensemble_genetic_test.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n"
     ]
    }
   ],
   "source": [
    "# Assembling benchmark based on VIEWS ensemble predictions\n",
    "sc_predictions_ensemble = []\n",
    "cm_ensemble_name = 'cm_ensemble_genetic_test'\n",
    "    \n",
    "ensemble_df = pd.DataFrame.forecasts.read_store(cm_ensemble_name, run=dev_id)[stepcols]\n",
    "ensemble_df.head()\n",
    "\n",
    "for year in year_list:\n",
    "    sc_dict = {\n",
    "        'year': year,\n",
    "        'prediction_df': extract_sc_predictions(year=year,ss_predictions=ensemble_df)\n",
    "    }\n",
    "    sc_predictions_ensemble.append(sc_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff33ed4",
   "metadata": {},
   "source": [
    "# pgm level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b6c2c192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_46_pgm_fatalities002_pgm_conflict_history_xgb_test.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/var/folders/yx/jx4m7bqx0m96x8cnzd8175kh0000gn/T/ipykernel_61150/294722920.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n"
     ]
    }
   ],
   "source": [
    "# Assembling benchmark based on VIEWS ensemble predictions\n",
    "sc_predictions_ensemble = []\n",
    "# any old pgm data\n",
    "pgm_ensemble_name = 'pgm_fatalities002_pgm_conflict_history_xgb_test'\n",
    "    \n",
    "ensemble_df = pd.DataFrame.forecasts.read_store(pgm_ensemble_name, run=dev_id)[stepcols]\n",
    "ensemble_df.head()\n",
    "\n",
    "for year in year_list:\n",
    "    sc_dict = {\n",
    "        'year': year,\n",
    "        'prediction_df': extract_sc_predictions(year=year,ss_predictions=ensemble_df)\n",
    "    }\n",
    "    sc_predictions_ensemble.append(sc_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "55678f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 s, sys: 11.1 s, total: 38.5 s\n",
      "Wall time: 42.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>draws</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_id</th>\n",
       "      <th>priogrid_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">457</th>\n",
       "      <th>62356</th>\n",
       "      <td>0.001027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62356</th>\n",
       "      <td>0.001027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62356</th>\n",
       "      <td>0.001027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62356</th>\n",
       "      <td>0.001027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62356</th>\n",
       "      <td>0.001027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">468</th>\n",
       "      <th>190511</th>\n",
       "      <td>0.001635</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190511</th>\n",
       "      <td>0.001635</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190511</th>\n",
       "      <td>0.001635</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190511</th>\n",
       "      <td>0.001635</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190511</th>\n",
       "      <td>0.001635</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157320000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      prediction draws\n",
       "month_id priogrid_id                  \n",
       "457      62356          0.001027     0\n",
       "         62356          0.001027     0\n",
       "         62356          0.001027     0\n",
       "         62356          0.001027     0\n",
       "         62356          0.001027     0\n",
       "...                          ...   ...\n",
       "468      190511         0.001635     0\n",
       "         190511         0.001635     0\n",
       "         190511         0.001635     0\n",
       "         190511         0.001635     0\n",
       "         190511         0.001635     0\n",
       "\n",
       "[157320000 rows x 2 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "test_data = sc_predictions_ensemble[0].get('prediction_df')\n",
    "test_data['draws'] = test_data.apply(function_with_draws, axis=1)\n",
    "test_data.explode('draws')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8bd551",
   "metadata": {},
   "source": [
    "### Based on constituent models\n",
    "\n",
    "Short version, 22 models: \n",
    "1 \"draw\"\n",
    "from each of 22 constituent models\n",
    "\n",
    "Plus version with 45 draws from Poisson distribution for each model.\n",
    "\n",
    "Possibly obsolete:\n",
    "Long version, 440 models:\n",
    "20 \"draws\" from each of 22 constituent models, using predictions for adjacent steps (from s-4 to s+6). Some duplications to weight the most proximate steps more.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989b764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fatalities002 stuff - contains the list of the current fatalities002 ensemble models\n",
    "\n",
    "from ModelDefinitions import DefineEnsembleModels\n",
    "\n",
    "level = 'cm'\n",
    "ModelList_cm = DefineEnsembleModels(level)\n",
    "ModelList_cm = ModelList_cm[0:20] # Drop Markov models\n",
    "\n",
    "i = 0\n",
    "for model in ModelList_cm:\n",
    "    print(i, model['modelname'], model['data_train'])\n",
    "    i = i + 1\n",
    "\n",
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "\n",
    "ModelList_cm = RetrieveStoredPredictions(ModelList_cm, steps, EndOfHistory, dev_id, level, get_future)\n",
    "\n",
    "ModelList_cm = CalibratePredictions(ModelList_cm, EndOfHistory, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec49db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelList_cm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2837f185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembling benchmark based on VIEWS constituent model predictions\n",
    "draws_per_model = np.floor_divide(draws_cm,len(ModelList_cm))\n",
    "for model in ModelList_cm:\n",
    "    print(model['modelname'])\n",
    "\n",
    "    model['sc_predictions_constituent'] = []\n",
    "\n",
    "    for year in year_list:\n",
    "        sc_dict = {\n",
    "            'year': year,\n",
    "            'prediction_df': extract_sc_predictions(year=year,ss_predictions=model['predictions_test_df'])\n",
    "        }\n",
    "        model['sc_predictions_constituent'].append(sc_dict)\n",
    "\n",
    "    # Expanding by drawing n draws from Poisson distribution   \n",
    "    for year_record in model['sc_predictions_constituent']:\n",
    "        print(year_record['year'])\n",
    "        year_record['expanded_df'] = expanded_predictions(sc_predictions = year_record['prediction_df'],draws = draws_per_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4793e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_predictions_constituent = []\n",
    "\n",
    "for year in year_list:\n",
    "    print(year)\n",
    "    print(ModelList_cm[0]['modelname'])\n",
    "    expanded_df = ModelList_cm[0]['sc_predictions_constituent'][year-2018]['expanded_df']\n",
    "#    print(expanded_df.describe())\n",
    "    i = 0\n",
    "    for model in ModelList_cm[1:19]:\n",
    "        print(model['modelname'])\n",
    "        expanded_df = pd.concat([expanded_df,model['sc_predictions_constituent'][year-2018]['expanded_df']])\n",
    "#        print(expanded_df.describe())\n",
    "        \n",
    "    sc_dict = {\n",
    "        'year': year,\n",
    "        'expanded_df': expanded_df\n",
    "    }\n",
    "    sc_predictions_constituent.append(sc_dict)\n",
    "    i = i + 1\n",
    "       \n",
    "#sc_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d26142",
   "metadata": {},
   "source": [
    "# Saving the cm benchmark models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['ensemble','constituent']\n",
    "i = 0\n",
    "for bm_model in [sc_predictions_ensemble,sc_predictions_constituent]:\n",
    "    for record in bm_model:\n",
    "        year_record = record # First part of record list is list of yearly predictions, second is string name for benchmark model\n",
    "        print(year_record['year'])\n",
    "        filename = filepath + 'bm_cm_' + model_names[i] + '_expanded_' + str(year_record['year']) + '.parquet'\n",
    "        print(filename)\n",
    "        year_record['expanded_df'].to_parquet(filename)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6acfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc_predictions_ensemble[0]['expanded_df']\n",
    "df[df['Poisson_sc']>0].describe()\n",
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6a00e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with actuals\n",
    "df_actuals = pd.DataFrame(ModelList_cm[0]['predictions_test_df']['ln_ged_sb_dep'])\n",
    "cm_actuals = df_actuals\n",
    "cm_actuals['ged_sb'] = np.expm1(cm_actuals['ln_ged_sb_dep'])\n",
    "cm_actuals.drop(columns=['ln_ged_sb_dep'], inplace=True)\n",
    "print(cm_actuals.head())\n",
    "print(cm_actuals.tail())\n",
    "print(cm_actuals.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e58b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annual dataframes with actuals, saved to disk\n",
    "for year in year_list:\n",
    "    first_month = (year - 1980)*12 + 1\n",
    "    last_month = (year - 1980 + 1)*12\n",
    "    df_annual = cm_actuals.loc[first_month:last_month]\n",
    "    filename = filepath + 'cm_actuals_' + str(year) + '.parquet'\n",
    "    print(year, first_month, last_month, filename)\n",
    "    print(df_annual.head())\n",
    "    df_annual.to_parquet(filename)\n",
    "# For all four years\n",
    "filename = filepath + 'cm_actuals_allyears.parquet'\n",
    "cm_actuals.to_parquet(filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6bcac5",
   "metadata": {},
   "source": [
    "# Old cm stuff from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e0952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_annual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe118d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_df_cm(df, draw):\n",
    "    ''' Drops steps we will not need in the benchmark model. \n",
    "    Another round of drops are done below '''\n",
    "    steps_to_drop = ['ln_ged_sb_dep','step_pred_25','step_pred_26','step_pred_27','step_pred_28','step_pred_29','step_pred_30',\n",
    "                     'step_pred_31','step_pred_32','step_pred_33','step_pred_34','step_pred_35','step_pred_36',]\n",
    "    df = df.drop(steps_to_drop,axis=1)\n",
    "    df.reset_index(inplace=True)\n",
    "    df['draw'] = draw\n",
    "    df_long = pd.wide_to_long(df, 'step_pred_', i = ['month_id', 'country_id'], j = 'step')\n",
    "    df_long.reset_index(inplace=True)\n",
    "    df_long.set_index(['month_id','country_id','step','draw'],inplace=True)\n",
    "    return(df_long)\n",
    "    \n",
    "model_draw = 0\n",
    "df = ModelList_cm[model_draw]['predictions_test_df'].copy()\n",
    "df_cm_results_long = reshape_df_cm(df,model_draw)\n",
    "print('Starting with model/draw',model_draw, model['modelname'])\n",
    "print(df_cm_results_long.describe())\n",
    "print(df_cm_results_long.head())\n",
    "\n",
    "\n",
    "for model in ModelList_cm[1:]:\n",
    "    model_draw += 1\n",
    "    print('Appending model/draw',model_draw, model['modelname'])\n",
    "    df = ModelList_cm[model_draw]['predictions_test_df'].copy()\n",
    "    df_reshaped = reshape_df_cm(df,model_draw)\n",
    "    df_cm_results_long = pd.concat([df_cm_results_long ,df_reshaped], axis=0)\n",
    "    \n",
    "\n",
    "df_cm_results_long['prediction'] = np.round_(np.expm1(df_cm_results_long['step_pred_'])).astype('int32')\n",
    "df_cm_results_long.drop(columns=['step_pred_'], inplace=True)\n",
    "# Results file in long format\n",
    "print(df_cm_results_long.describe())\n",
    "print(df_cm_results_long.tail())\n",
    "\n",
    "print(df_cm_results_long.loc[492].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1871a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cm_final_extended = df_cm_results_long.copy()\n",
    "\n",
    "def make_dfcopy_cm(df_in, step, shifted_step, repetition):\n",
    "    ''' Makes a 'copy' of the df with a shifted step '''\n",
    "#    print(step, shifted_step, repetition)\n",
    "    df = pd.DataFrame(df_in[df_in.index.get_level_values('step').isin([shifted_step])]).copy()\n",
    "    df.reset_index(inplace = True)\n",
    "    df['step'].replace(shifted_step, step, inplace = True)\n",
    "#    print(df.describe())\n",
    "    df['draw'] = (df['draw'] + len(ModelList_cm) * repetition)\n",
    "#    print(df.describe())\n",
    "    df.set_index(['month_id', 'country_id', 'step', 'draw'], inplace=True)\n",
    "    return(df)\n",
    "    \n",
    "df_list_steps = []\n",
    "df_list_steps.append(df_cm_results_long)\n",
    "for step in range(3,14+1):     \n",
    "#    print(80*'*')\n",
    "    print('Step', step)\n",
    "    df = pd.DataFrame(df_cm_results_long[df_cm_results_long.index.get_level_values('step').isin([step])])\n",
    "#    print(df.head(3))\n",
    "    repetition = 1\n",
    "    df_list = []\n",
    "    for shift in [(-4,2),(-3,4),(-2,5),(-1,6),(0,6),(1,5),(2,4),(3,3),(4,2),(5,2),(6,2),(7,1),(8,1),(9,1)]:\n",
    "        for copy in range(1,shift[1]+1):\n",
    "            shifted_step = step+shift[0]\n",
    "            if shifted_step < 1:\n",
    "                shifted_step = step\n",
    "            step_list = [shifted_step]\n",
    "            df = make_dfcopy_cm(df_in = df_cm_results_long,step = step, shifted_step = shifted_step, repetition = repetition)\n",
    "            df_list.append(df)\n",
    "            repetition += 1\n",
    "    df_cm_temp = pd.concat(df_list)\n",
    "    df_list_steps.append(df_cm_temp)\n",
    "\n",
    "df_cm_final_extended = pd.concat(df_list_steps)\n",
    "#df.reorder_levels(['month_id','country_id','steps','draw'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb476c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_ss48_to_sc12(df, level,firstmonth,years):\n",
    "    ''' Converts a dataframe in long format from one including all VIEWS ss predictions \n",
    "        into a set of dataframes containing only sc predictions for 12 months '''\n",
    "    df_list = []\n",
    "    for year in range(1,years+1):\n",
    "        this_firstmonth = firstmonth + (year-1)*12\n",
    "        print(year, this_firstmonth)\n",
    "#        this_df = df.query(f'month_id >= {this_firstmonth} and month_id <= {this_firstmonth+12-1}')\n",
    "        month_df_list = []\n",
    "        for step in range(3,14+1):\n",
    "            select_month = this_firstmonth + step - 3\n",
    "#            print('retaining month',select_month,'step',step)\n",
    "            month_df = df.query(f'month_id == {select_month} and step == {step}')\n",
    "            month_df_list.append(month_df)\n",
    "        year_df = pd.concat(month_df_list)\n",
    "        df_list.append(year_df)\n",
    "    return(df_list)\n",
    "\n",
    "    \n",
    "cm_ensemble_predictions = from_ss48_to_sc12(df_cm_final_extended,'cm',445,4)\n",
    "\n",
    "cm_ensemble_predictions[1].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6d92db",
   "metadata": {},
   "source": [
    "### cm last historical values benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c89361",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = (Queryset(\"benchmark_cm\", \"country_month\")\n",
    "\n",
    "   # target variable\n",
    "   .with_column(Column(\"ged_sb\", from_table=\"ged2_cm\", from_column=\"ged_sb_best_sum_nokgi\")\n",
    "                .transform.missing.fill()\n",
    "                .transform.missing.replace_na()\n",
    "                )\n",
    "\n",
    "\n",
    "   .with_theme(\"benchmark\")\n",
    "   .describe(\"\"\"Data for empirical benchmark model, cm level\n",
    "\n",
    "\n",
    "            \"\"\")\n",
    "   )\n",
    "\n",
    "#queryset = Queryset(\"name\", \"loa\") # if not already defined\n",
    "column = \"ged_sb_best_sum_nokgi\"\n",
    "table = \"ged2_cm\"\n",
    "lags=range(1,65)\n",
    "for lag in lags: \n",
    "    qs = qs.with_column(Column(column+'_' + str(lag), from_table = table, from_column=column)\n",
    "                        .transform.missing.replace_na()\n",
    "                        .transform.temporal.tlag(lag)\n",
    "                       )\n",
    "df_cm_historical_values = qs.publish().fetch()\n",
    "df_cm_historical_values = df_cm_historical_values.loc[445:492]\n",
    "\n",
    "df_cm_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafdd362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating predictions for test partition\n",
    "number_of_lags = 45\n",
    "maxstep = 14\n",
    "df_list_bystep = []\n",
    "for step in range(3,maxstep+1):\n",
    "    lags=range(step,step + number_of_lags)\n",
    "    draw = 0\n",
    "    print('step:',step,'lag:',lag, 'draw:',draw)\n",
    "    df_list = []\n",
    "    for lag in lags:\n",
    "        number_of_repetitions = number_of_lags+step-lag\n",
    "#        print('lag:',lag,'repetitions:',number_of_repetitions)\n",
    "#        print('step:',step,'lag:',lag, 'draw:',draw)\n",
    "        for repetition in range(1,number_of_repetitions):\n",
    "            lagged_col = 'ged_sb_best_sum_nokgi_' + str(lag)\n",
    "            df = pd.DataFrame(df_cm_historical_values[lagged_col].copy())\n",
    "            df.reset_index(inplace=True)\n",
    "            df['prediction'] = df[lagged_col]\n",
    "#            print(df.head())\n",
    "            df.drop(columns=[lagged_col], inplace=True)\n",
    "            df['step'] = step\n",
    "            df['draw'] = draw\n",
    "            df.set_index(['month_id', 'country_id', 'step','draw'], inplace=True)\n",
    "            df_list.append(df)\n",
    "#            if draw == 1 and step == 1:\n",
    "#                df_cm_predictions_historical_values = df.copy()\n",
    "#            else:\n",
    "#                df_cm_predictions_historical_values = pd.concat([df_cm_predictions_historical_values,df])\n",
    "            draw = draw + 1\n",
    "    df_cm_predictions_lag = pd.concat(df_list)\n",
    "    df_list_bystep.append(df_cm_predictions_lag)\n",
    "    print('Number of draws:',draw + 1)\n",
    "df_cm_predictions_historical_values = pd.concat(df_list_bystep) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e2923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cm_predictions_historical_values.describe())\n",
    "print(df_cm_predictions_historical_values.head())\n",
    "print(df_cm_predictions_historical_values.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f710d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_historical_values_predictions = from_ss48_to_sc12(df_cm_predictions_historical_values,'cm',445,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ab3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_and_categorize(df, level):\n",
    "    ''' This function aggregates the input df across all draws, and returns summary statistics for the prediction model '''\n",
    "    if level == 'cm':\n",
    "        index = ['month_id','country_id']\n",
    "    if level == 'pgm':\n",
    "        index = ['month_id', 'priogrid_gid']\n",
    "    if level == 'pgm2':\n",
    "        index = ['month_id', 'priogrid_id']\n",
    "    df_to_aggregate = df.copy()\n",
    "    df_to_aggregate['log_prediction'] = np.log1p(df_to_aggregate['prediction'] )\n",
    "\n",
    "    # Proportion of draws in fatality categories\n",
    "    #for cutoffs in [0,1,10,100,1000,10000]:\n",
    "    bins = pd.IntervalIndex.from_tuples([(-1, 0), (1, 10), (11, 100), (101, 1000), (1001, 10000), (10001,100000000)])\n",
    "    df_to_aggregate['categorical'] = pd.cut(df_to_aggregate['prediction'],bins)\n",
    "    df_to_aggregate_dummies = pd.get_dummies(df_to_aggregate['categorical'],prefix='cat')\n",
    "    df_to_aggregate = pd.concat([df_to_aggregate,df_to_aggregate_dummies],axis=1)\n",
    "\n",
    "    # Mean and standard deviation of log predictions\n",
    "    df_aggregated = pd.DataFrame(df_to_aggregate['log_prediction'].groupby(level=index).mean())\n",
    "    df_aggregated.rename(columns={'log_prediction':'mean_log_prediction'},inplace=True)\n",
    "    df_aggregated['std_log_prediction'] = df_to_aggregate['log_prediction'].groupby(level=index).std()\n",
    "    for col in ('cat_(-1, 0]','cat_(1, 10]','cat_(11, 100]','cat_(101, 1000]','cat_(1001, 10000]','cat_(10001, 100000000]'):\n",
    "        df_aggregated[col] = df_to_aggregate[col].groupby(level=index).mean()\n",
    "    return(df_aggregated)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65a2957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate across draws/samples to extract means, standard deviations, and category probabilities\n",
    "df_cm_predictions_historical_values_aggregated = aggregate_and_categorize(df_cm_predictions_historical_values,'cm')\n",
    "df_cm_predictions_ensemble_aggregated = aggregate_and_categorize(df_cm_final_extended,'cm')\n",
    "\n",
    "print(df_cm_predictions_historical_values_aggregated.describe())\n",
    "print(df_cm_predictions_historical_values_aggregated.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfa3d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Saving the annual sc files and the aggregated versions of them\n",
    "filepath = Mydropbox + 'Prediction_competition_2023/'\n",
    "year = 2018\n",
    "for df in cm_historical_values_predictions:\n",
    "    # Simplifying the indices: removing the step column\n",
    "    print('cm_historical', year)\n",
    "    df = df.reset_index()\n",
    "    df.set_index(['month_id','country_id','draw'],inplace=True)\n",
    "    df.drop(columns=['step'],inplace=True)\n",
    "    df['prediction'] = df['prediction'].astype('int32') \n",
    "    print(df.head())\n",
    "    print(df.dtypes)\n",
    "    filename = filepath + 'bm_cm_historical_values_' + str(year) + '.parquet'\n",
    "    print(filename)\n",
    "    df.to_parquet(filename)\n",
    "    df_aggregated = aggregate_and_categorize(df,'cm')\n",
    "    filename = filepath + 'bm_cm_historical_values_agg' + str(year) + '.parquet'\n",
    "    df_aggregated.to_parquet(filename)\n",
    "    year = year + 1\n",
    "year = 2018\n",
    "for df in cm_ensemble_predictions:\n",
    "    print('cm_ensemble', year)\n",
    "    df = df.reset_index()\n",
    "    df.set_index(['month_id','country_id','draw'],inplace=True)\n",
    "    df.drop(columns=['step'],inplace=True)\n",
    "    df['prediction'] = df['prediction'].astype('int32') \n",
    "    filename = filepath + 'bm_cm_ensemble_' + str(year) + '.parquet'\n",
    "    print(filename)\n",
    "    df.to_parquet(filename)\n",
    "    df_aggregated = aggregate_and_categorize(df,'cm')\n",
    "    filename = filepath + 'bm_cm_ensemble_agg' + str(year) + '.parquet'\n",
    "    df_aggregated.to_parquet(filename)\n",
    "    year = year + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13036c96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947356fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "include_expansive = False\n",
    "\n",
    "if include_expansive:\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_actuals.parquet'\n",
    "    cm_actuals.to_parquet(filename)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_ensemble_22.parquet'\n",
    "    df_cm_results_long_pruned.to_parquet(filename)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_ensemble_550.parquet'\n",
    "    df_cm_final_extended.to_parquet(filename)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_ensemble_550_aggregated.parquet'\n",
    "    df_cm_predictions_ensemble_aggregated.to_parquet(filename)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_benchmark_historical_values.parquet'\n",
    "    df_cm_predictions_historical_values.to_parquet(filename)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'cm_predictions_historical_values_aggregated.parquet'\n",
    "    df_cm_predictions_historical_values_aggregated.to_parquet(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51884343",
   "metadata": {},
   "source": [
    "# pgm level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4178e6ae",
   "metadata": {},
   "source": [
    "### Based on ensemble; expanded using a Poisson draw with mean=variance=\\hat{y}_{it}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9921996c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pr_46_pgm_ensemble_cm_calib_test.parquet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bz/1cx7kmbj2919xmdqxy83mbs80000gp/T/ipykernel_62916/294722920.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/var/folders/bz/1cx7kmbj2919xmdqxy83mbs80000gp/T/ipykernel_62916/294722920.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/var/folders/bz/1cx7kmbj2919xmdqxy83mbs80000gp/T/ipykernel_62916/294722920.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/var/folders/bz/1cx7kmbj2919xmdqxy83mbs80000gp/T/ipykernel_62916/294722920.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n",
      "/var/folders/bz/1cx7kmbj2919xmdqxy83mbs80000gp/T/ipykernel_62916/294722920.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['prediction'] = np.expm1(df_temp[this_col].values)\n",
      "/var/folders/bz/1cx7kmbj2919xmdqxy83mbs80000gp/T/ipykernel_62916/294722920.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['prediction'].loc[this_month] = df_temp['prediction'].values\n"
     ]
    }
   ],
   "source": [
    "# Assembling benchmark based on VIEWS ensemble predictions\n",
    "sc_predictions_ensemble_pgm = []\n",
    "pgm_ensemble_name = 'pgm_ensemble_cm_calib_test'\n",
    "    \n",
    "ensemble_pgm_df = pd.DataFrame.forecasts.read_store(pgm_ensemble_name, run=dev_id)[stepcols]\n",
    "ensemble_pgm_df.head()\n",
    "\n",
    "for year in year_list[0:3]:\n",
    "    sc_dict = {\n",
    "        'year': year,\n",
    "        'prediction_df': extract_sc_predictions(year=year,ss_predictions=ensemble_pgm_df)\n",
    "    }\n",
    "    sc_predictions_ensemble_pgm.append(sc_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5889e06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ln_ged_sb_dep</th>\n",
       "      <th>step_pred_3</th>\n",
       "      <th>step_pred_4</th>\n",
       "      <th>step_pred_5</th>\n",
       "      <th>step_pred_6</th>\n",
       "      <th>step_pred_7</th>\n",
       "      <th>step_pred_8</th>\n",
       "      <th>step_pred_9</th>\n",
       "      <th>step_pred_10</th>\n",
       "      <th>step_pred_11</th>\n",
       "      <th>step_pred_12</th>\n",
       "      <th>step_pred_13</th>\n",
       "      <th>step_pred_14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month_id</th>\n",
       "      <th>priogrid_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">445</th>\n",
       "      <th>62356</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79599</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79600</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79601</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80317</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ln_ged_sb_dep  step_pred_3  step_pred_4  step_pred_5  \\\n",
       "month_id priogrid_id                                                         \n",
       "445      62356                  0.0          0.0          0.0          0.0   \n",
       "         79599                  0.0          0.0          0.0          0.0   \n",
       "         79600                  0.0          0.0          0.0          0.0   \n",
       "         79601                  0.0          0.0          0.0          0.0   \n",
       "         80317                  0.0          0.0          0.0          0.0   \n",
       "\n",
       "                      step_pred_6  step_pred_7  step_pred_8  step_pred_9  \\\n",
       "month_id priogrid_id                                                       \n",
       "445      62356                0.0          0.0          0.0          0.0   \n",
       "         79599                0.0          0.0          0.0          0.0   \n",
       "         79600                0.0          0.0          0.0          0.0   \n",
       "         79601                0.0          0.0          0.0          0.0   \n",
       "         80317                0.0          0.0          0.0          0.0   \n",
       "\n",
       "                      step_pred_10  step_pred_11  step_pred_12  step_pred_13  \\\n",
       "month_id priogrid_id                                                           \n",
       "445      62356                 0.0           0.0           0.0           0.0   \n",
       "         79599                 0.0           0.0           0.0           0.0   \n",
       "         79600                 0.0           0.0           0.0           0.0   \n",
       "         79601                 0.0           0.0           0.0           0.0   \n",
       "         80317                 0.0           0.0           0.0           0.0   \n",
       "\n",
       "                      step_pred_14  \n",
       "month_id priogrid_id                \n",
       "445      62356                 0.0  \n",
       "         79599                 0.0  \n",
       "         79600                 0.0  \n",
       "         79601                 0.0  \n",
       "         80317                 0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_pgm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb07bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 7300 7400 7500 7600 7700 7800 7900 8000 8100 8200 8300 8400 8500 8600 8700 8800 8900 9000 9100 9200 9300 9400 9500 9600 9700 9800 9900 10000 10100 10200 10300 10400 10500 10600 10700 10800 10900 11000 11100 11200 11300 11400 11500 11600 11700 11800 11900 12000 12100 12200 12300 12400 12500 12600 12700 12800 12900 13000 13100 13200 13300 13400 13500 13600 13700 13800 13900 14000 14100 14200 14300 14400 14500 14600 14700 14800 14900 15000 15100 15200 15300 15400 15500 15600 15700 15800 15900 16000 16100 16200 16300 16400 16500 16600 16700 16800 16900 17000 17100 17200 17300 17400 17500 17600 17700 17800 17900 18000 18100 18200 18300 18400 18500 18600 18700 18800 18900 19000 19100 19200 19300 19400 19500 19600 19700 19800 19900 20000 20100 20200 20300 20400 20500 20600 20700 20800 20900 21000 21100 21200 21300 21400 21500 21600 21700 21800 21900 22000 22100 22200 22300 22400 22500 22600 22700 22800 22900 23000 23100 23200 23300 23400 23500 23600 23700 23800 23900 24000 24100 24200 24300 24400 24500 24600 24700 24800 24900 25000 25100 25200 25300 25400 25500 25600 25700 25800 25900 26000 26100 26200 26300 26400 26500 26600 26700 26800 26900 27000 27100 27200 27300 27400 27500 27600 27700 27800 27900 28000 28100 28200 28300 28400 28500 28600 28700 28800 28900 29000 29100 29200 29300 29400 29500 29600 29700 29800 29900 30000 30100 30200 30300 30400 30500 30600 30700 30800 30900 31000 31100 31200 31300 31400 31500 31600 31700 31800 31900 32000 32100 32200 32300 32400 32500 32600 32700 32800 32900 33000 33100 33200 33300 33400 33500 33600 33700 33800 33900 34000 34100 34200 34300 34400 34500 34600 34700 34800 34900 35000 35100 35200 35300 35400 35500 35600 35700 35800 35900 36000 36100 36200 36300 36400 36500 36600 36700 36800 36900 37000 37100 37200 37300 37400 37500 37600 37700 37800 37900 38000 38100 38200 38300 38400 38500 38600 38700 38800 38900 39000 39100 39200 39300 39400 39500 39600 39700 39800 39900 40000 40100 40200 40300 40400 40500 40600 40700 40800 40900 41000 41100 41200 41300 41400 41500 41600 41700 41800 41900 42000 42100 42200 42300 42400 42500 42600 42700 42800 42900 43000 43100 43200 43300 43400 43500 43600 43700 43800 43900 44000 44100 44200 44300 44400 44500 44600 44700 44800 44900 45000 45100 45200 45300 45400 45500 45600 45700 45800 45900 46000 46100 46200 46300 46400 46500 46600 46700 46800 46900 47000 47100 47200 47300 47400 47500 47600 47700 47800 47900 48000 48100 48200 48300 48400 48500 48600 48700 48800 48900 49000 49100 49200 49300 49400 49500 49600 49700 49800 49900 50000 50100 50200 50300 50400 50500 50600 50700 50800 50900 51000 51100 51200 51300 51400 51500 51600 51700 51800 51900 52000 52100 52200 52300 52400 52500 52600 52700 52800 52900 53000 53100 53200 53300 53400 53500 53600 53700 53800 53900 54000 54100 54200 54300 54400 54500 54600 54700 54800 54900 55000 55100 55200 55300 55400 55500 55600 55700 55800 55900 56000 56100 56200 56300 56400 56500 56600 56700 56800 56900 57000 57100 57200 57300 57400 57500 57600 57700 57800 57900 58000 58100 58200 58300 58400 58500 58600 58700 58800 58900 59000 59100 59200 59300 59400 59500 59600 59700 59800 59900 60000 60100 60200 60300 60400 60500 60600 60700 60800 60900 61000 61100 61200 61300 61400 61500 61600 61700 61800 61900 62000 62100 62200 62300 62400 62500 62600 62700 62800 62900 63000 63100 63200 63300 63400 63500 63600 63700 63800 63900 64000 64100 64200 64300 64400 64500 64600 64700 64800 64900 65000 65100 65200 65300 65400 65500 65600 65700 65800 65900 66000 66100 66200 66300 66400 66500 66600 66700 66800 66900 67000 67100 67200 67300 67400 67500 67600 67700 67800 67900 68000 68100 68200 68300 68400 68500 68600 68700 68800 68900 69000 69100 69200 69300 69400 69500 69600 69700 69800 69900 70000 70100 70200 70300 70400 70500 70600 70700 70800 70900 71000 71100 71200 71300 71400 71500 71600 71700 71800 71900 72000 72100 72200 72300 72400 72500 72600 72700 72800 72900 73000 73100 73200 73300 73400 73500 73600 73700 73800 73900 74000 74100 74200 74300 74400 74500 74600 74700 74800 74900 75000 75100 75200 75300 75400 75500 75600 75700 75800 75900 76000 76100 76200 76300 76400 76500 76600 76700 76800 76900 77000 77100 77200 77300 77400 77500 77600 77700 77800 77900 78000 78100 78200 78300 78400 78500 78600 78700 78800 78900 79000 79100 79200 79300 79400 79500 79600 79700 79800 79900 80000 80100 80200 80300 80400 80500 80600 80700 80800 80900 81000 81100 81200 81300 81400 81500 81600 81700 81800 81900 82000 82100 82200 82300 82400 82500 82600 82700 82800 82900 83000 83100 83200 83300 83400 83500 83600 83700 83800 83900 84000 84100 84200 84300 84400 84500 84600 84700 84800 84900 85000 85100 85200 85300 85400 85500 85600 85700 85800 85900 86000 86100 86200 86300 86400 86500 86600 86700 86800 86900 87000 87100 87200 87300 87400 87500 87600 87700 87800 87900 88000 88100 88200 88300 88400 88500 88600 88700 88800 88900 89000 89100 89200 89300 89400 89500 89600 89700 89800 89900 90000 90100 90200 90300 90400 90500 90600 90700 90800 90900 91000 91100 91200 91300 91400 91500 91600 91700 91800 91900 92000 92100 92200 92300 92400 92500 92600 92700 92800 92900 93000 93100 93200 93300 93400 93500 93600 93700 93800 93900 94000 94100 94200 94300 94400 94500 94600 94700 94800 94900 95000 95100 95200 95300 95400 95500 95600 95700 95800 95900 96000 96100 96200 96300 96400 96500 96600 96700 96800 96900 97000 97100 97200 97300 97400 97500 97600 97700 97800 97900 98000 98100 98200 98300 98400 98500 98600 98700 98800 98900 99000 99100 99200 99300 99400 99500 99600 99700 99800 99900 100000 100100 100200 100300 100400 100500 100600 100700 100800 100900 101000 101100 101200 101300 101400 101500 101600 101700 101800 101900 102000 102100 102200 102300 102400 102500 102600 102700 102800 102900 103000 103100 103200 103300 103400 103500 103600 103700 103800 103900 104000 104100 104200 104300 104400 104500 104600 104700 104800 104900 105000 105100 105200 105300 105400 105500 105600 105700 105800 105900 106000 106100 106200 106300 106400 106500 106600 106700 106800 106900 107000 107100 107200 107300 107400 107500 107600 107700 107800 107900 108000 108100 108200 108300 108400 108500 108600 108700 108800 108900 109000 109100 109200 109300 109400 109500 109600 109700 109800 109900 110000 110100 110200 110300 110400 110500 110600 110700 110800 110900 111000 111100 111200 111300 111400 111500 111600 111700 111800 111900 112000 112100 112200 112300 112400 112500 112600 112700 112800 112900 113000 113100 113200 113300 113400 113500 113600 113700 113800 113900 114000 114100 114200 114300 114400 114500 114600 114700 114800 114900 115000 115100 115200 115300 115400 115500 115600 115700 115800 115900 116000 116100 116200 116300 116400 116500 116600 116700 116800 116900 117000 117100 117200 117300 117400 117500 117600 117700 117800 117900 118000 118100 118200 118300 118400 118500 118600 118700 118800 118900 119000 119100 119200 119300 119400 119500 119600 119700 119800 119900 120000 120100 120200 120300 120400 120500 120600 120700 120800 120900 121000 121100 121200 121300 121400 121500 121600 121700 121800 121900 122000 122100 122200 122300 122400 122500 122600 122700 122800 122900 123000 123100 123200 123300 123400 123500 123600 123700 123800 123900 124000 124100 124200 124300 124400 124500 124600 124700 124800 124900 125000 125100 125200 125300 125400 125500 125600 125700 125800 125900 126000 126100 126200 126300 126400 126500 126600 126700 126800 126900 127000 127100 127200 127300 127400 127500 127600 127700 127800 127900 128000 128100 128200 128300 128400 128500 128600 128700 128800 128900 129000 129100 129200 129300 129400 129500 129600 129700 129800 129900 130000 130100 130200 130300 130400 130500 130600 130700 130800 130900 131000 131100 131200 131300 131400 131500 131600 131700 131800 131900 132000 132100 132200 132300 132400 132500 132600 132700 132800 132900 133000 133100 133200 133300 133400 133500 133600 133700 133800 133900 134000 134100 134200 134300 134400 134500 134600 134700 134800 134900 135000 135100 135200 135300 135400 135500 135600 135700 135800 135900 136000 136100 136200 136300 136400 136500 136600 136700 136800 136900 137000 137100 137200 137300 137400 137500 137600 137700 137800 137900 138000 138100 138200 138300 138400 138500 138600 138700 138800 138900 139000 139100 139200 139300 139400 139500 139600 139700 139800 139900 140000 140100 140200 140300 140400 140500 140600 140700 140800 140900 141000 141100 141200 141300 141400 141500 141600 141700 141800 141900 142000 142100 142200 142300 142400 142500 142600 142700 142800 142900 143000 143100 143200 143300 143400 143500 143600 143700 143800 143900 144000 144100 144200 144300 144400 144500 144600 144700 144800 144900 145000 145100 145200 145300 145400 145500 145600 145700 145800 145900 146000 146100 146200 146300 146400 146500 146600 146700 146800 146900 147000 147100 147200 147300 147400 147500 147600 147700 147800 147900 148000 148100 148200 148300 148400 148500 148600 148700 148800 148900 149000 149100 149200 149300 149400 149500 149600 149700 149800 149900 150000 150100 150200 150300 150400 150500 150600 150700 150800 150900 151000 151100 151200 151300 151400 151500 151600 151700"
     ]
    }
   ],
   "source": [
    "# Expanding by drawing n draws from Poisson distribution   \n",
    "for year_record in sc_predictions_ensemble_pgm:\n",
    "    print(year_record['year'])\n",
    "    year_record['expanded_df'] = expanded_predictions(sc_predictions = year_record['prediction_df'],draws = draws_pgm, level = 'pgm')\n",
    "\n",
    "describe_expanded(df=sc_predictions_ensemble[0]['prediction_df'], df_expanded=sc_predictions_ensemble[0]['expanded_df'], month=457, country=57)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b14afc",
   "metadata": {},
   "source": [
    "# Old pgm stuff from here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea38184",
   "metadata": {},
   "source": [
    "## Ensemble model pgm benchmark\n",
    "\n",
    "kj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e78ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "level = 'pgm'\n",
    "ModelList_pgm = DefineEnsembleModels(level)\n",
    "    \n",
    "i = 0\n",
    "for model in ModelList_pgm:\n",
    "    print(i, model['modelname'], model['data_train'])\n",
    "    i = i + 1\n",
    "    \n",
    "# Retrieving the predictions for calibration and test partitions\n",
    "# The ModelList contains the predictions organized by model\n",
    "from Ensembling import CalibratePredictions, RetrieveStoredPredictions, mean_sd_calibrated, gam_calibrated\n",
    "\n",
    "ModelList_pgm = RetrieveStoredPredictions(ModelList_pgm, steps, EndOfHistory, dev_id, level, get_future)\n",
    "\n",
    "#ModelList_pgm = CalibratePredictions(ModelList_pgm, EndOfHistory, steps)\n",
    "\n",
    "# Dataframe with actuals\n",
    "df_actuals_pgm = pd.DataFrame(ModelList_pgm[0]['predictions_test_df']['ln_ged_sb_dep'])\n",
    "print(df_actuals_pgm.head())\n",
    "print(df_actuals_pgm.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48259249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping\n",
    "def reshape_df_pgm(df, draw):\n",
    "    ''' Drops steps we will not need in the benchmark model. \n",
    "    Another round of drops are done below '''\n",
    "    steps_to_drop = ['ln_ged_sb_dep','step_pred_23','step_pred_24',\n",
    "                     'step_pred_25','step_pred_26','step_pred_27','step_pred_28','step_pred_29','step_pred_30',\n",
    "                     'step_pred_31','step_pred_32','step_pred_33','step_pred_34','step_pred_35','step_pred_36',]\n",
    "    df = df.drop(steps_to_drop,axis=1)\n",
    "    df.reset_index(inplace=True)\n",
    "    df['draw'] = draw\n",
    "    df_long = pd.wide_to_long(df, 'step_pred_', i = ['month_id', 'priogrid_id', 'draw'], j = 'step')\n",
    "    return(df_long)\n",
    "\n",
    "model_draw = 0\n",
    "df = ModelList_pgm[model_draw]['predictions_test_df'].copy()\n",
    "df_pgm_results_long = reshape_df_pgm(df,model_draw)\n",
    "print('Starting with model/draw',model_draw, model['modelname'])\n",
    "print(df_pgm_results_long.describe())\n",
    "\n",
    "\n",
    "for model in ModelList_pgm[1:]:\n",
    "    model_draw += 1\n",
    "    print('Appending model/draw',model_draw, model['modelname'])\n",
    "    df = ModelList_pgm[model_draw]['predictions_test_df'].copy()\n",
    "    df_reshaped = reshape_df_pgm(df,model_draw)\n",
    "    df_pgm_results_long = pd.concat([df_pgm_results_long ,df_reshaped], axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963b6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_results_long['prediction'] = np.round_(np.expm1(df_pgm_results_long['step_pred_'])).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fcee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_results_long.drop(columns=['step_pred_'], inplace=True)\n",
    "#df_pgm_results_extended.index.set_names('priogrid_gid', level=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cd78f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results file in long format\n",
    "print(df_pgm_results_long.describe())\n",
    "print(df_pgm_results_long.tail())\n",
    "\n",
    "print(df_pgm_results_long.loc[492].describe())\n",
    "\n",
    "# Extending by copying adjacent steps\n",
    "\n",
    "df_pgm_results_extended=df_pgm_results_long.copy()\n",
    "\n",
    "print(df_pgm_results_extended.describe())\n",
    "print(df_pgm_results_extended.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba44b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into separate files by step\n",
    "df_ensembles_pgm_by_step = []\n",
    "for step in range(3,14+1):\n",
    "    print(step)\n",
    "    df = df_pgm_results_extended.xs(step, level=3).copy()\n",
    "    #print(df.describe())\n",
    "    df_ensembles_pgm_by_step.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4549533",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_dfcopy_pgm(df_in, step, shifted_step, repetition):\n",
    "    ''' Makes a 'copy' of the df with a shifted step '''\n",
    "#    print(step, shifted_step, repetition)\n",
    "    df = pd.DataFrame(df_in[df_in.index.get_level_values('step').isin([shifted_step])]).copy()\n",
    "    df.reset_index(inplace = True)\n",
    "    df['step'].replace(shifted_step, step, inplace = True)\n",
    "#    print(df.describe())\n",
    "    df['draw'] = (df['draw'] + len(ModelList_pgm) * repetition)\n",
    "#    print(df.describe())\n",
    "    df.set_index(['month_id', 'priogrid_id', 'step', 'draw'], inplace=True)\n",
    "    return(df)\n",
    "\n",
    "for step in range(3,14+1):     \n",
    "    print(80*'*')\n",
    "    print('Step', step, '-- Original dataframe for step', step, 'is:')\n",
    "    df = pd.DataFrame(df_pgm_results_extended[df_pgm_results_extended.index.get_level_values('step').isin([step])])\n",
    "    print(df.describe())\n",
    "    repetition = 1\n",
    "    df_list_pgm = []\n",
    "    for shift in [(-4,1),(-3,1),(-2,3),(-1,4),(0,3),(1,3),(2,2),(3,2),(4,1),(5,1),(6,1),(7,1),(8,1)]:\n",
    "        for copy in range(1,shift[1]+1):\n",
    "            shifted_step = step+shift[0]\n",
    "            if shifted_step < 1:\n",
    "                shifted_step = step\n",
    "            step_list = [shifted_step]\n",
    "            df = make_dfcopy_pgm(df_in = df_pgm_results_extended,step = step, shifted_step = shifted_step, repetition = repetition)\n",
    "            df_list_pgm.append(df)\n",
    "            repetition += 1\n",
    "    df_pgm_temp = pd.concat(df_list_pgm)\n",
    "    print('Extended:')\n",
    "    print(df_pgm_temp.describe())\n",
    "    # Export to parquet\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_ensemble_step_' + str(step) + '.parquet'\n",
    "    df_pgm_temp.to_parquet(filename)\n",
    "    # Aggregate across draws, save    \n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_ensemble_step_' + str(step) + '_aggregated.parquet'\n",
    "    df_aggregated_pgm = aggregate_and_categorize(df_pgm_temp,'pgm2')\n",
    "    print('Aggregated:')\n",
    "    print(df_aggregated_pgm.describe())\n",
    "    df_aggregated_pgm.to_parquet(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635b3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sc prediction files for ensemble model\n",
    "pgm_ensemble_predictions = from_ss48_to_sc12(df_pgm_results_extended,'pgm2',445,4)\n",
    "\n",
    "# Saving the annual sc files and the aggregated versions of them\n",
    "filepath = Mydropbox + 'Prediction_competition_2023/'\n",
    "year = 2018\n",
    "for df in pgm_ensemble_predictions:\n",
    "    filename = filepath + 'bm_pgm_ensemble_' + str(year) + '.parquet'\n",
    "    print(filename)\n",
    "    df.to_parquet(filename)\n",
    "    df_aggregated = aggregate_and_categorize(df,'pgm')\n",
    "    filename = filepath + 'bm_pgm_ensemble_agg' + str(year) + '.parquet'\n",
    "    df_aggregated.to_parquet(filename)\n",
    "    year = year + 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4be4904",
   "metadata": {},
   "source": [
    "## Historical values pgm benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55417594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lag settings (number of temporal lags at each spatial lag level)\n",
    "tlags_cell = 40\n",
    "tlags_firstorder = 27\n",
    "tlags_secondorder = 21\n",
    "\n",
    "# Spatial lags, first-order lag 1:\n",
    "kernel_inner=1\n",
    "kernel_width=1\n",
    "kernel_power=0\n",
    "norm_kernel=0\n",
    "\n",
    "rerun_querysets = False\n",
    "\n",
    "def retrieve_qs(qs_to_retrieve=qs,rerun=True,filename=''):\n",
    "    if rerun:\n",
    "        df = qs_to_retrieve.publish().fetch().loc[445:492]    \n",
    "        df.to_parquet(filename)\n",
    "    else:\n",
    "        df = pd.read_parquet(filename)\n",
    "    return(df)\n",
    "    \n",
    "\n",
    "print('Retrieving data for inner cells')\n",
    "\n",
    "column = \"ged_sb_best_sum_nokgi\"\n",
    "table = \"ged2_pgm\"\n",
    "\n",
    "qs = (Queryset(\"benchmark_pgm\", \"priogrid_month\")\n",
    "\n",
    "   # target variable at t0\n",
    "   .with_column(Column(\"ged_sb\", from_table=\"ged2_pgm\", from_column=\"ged_sb_best_sum_nokgi\")\n",
    "                .transform.missing.fill()\n",
    "                .transform.missing.replace_na()\n",
    "                )\n",
    "    # spatial lag at t0\n",
    "   .with_column(Column(\"splag_ged_sb_0\", from_table = table, from_column = column)\n",
    "                     .transform.missing.replace_na()\n",
    "                     .transform.spatial.lag(kernel_inner,kernel_width,kernel_power,norm_kernel)\n",
    "                    )\n",
    "\n",
    "\n",
    "   .with_theme(\"benchmark\")\n",
    "   .describe(\"\"\"Data for empirical benchmark model, pgm level\n",
    "            \"\"\")\n",
    "   )\n",
    "\n",
    "#queryset = Queryset(\"name\", \"loa\") # if not already defined\n",
    "column = \"ged_sb_best_sum_nokgi\"\n",
    "table = \"ged2_pgm\"\n",
    "tlags_0=range(1,tlags_cell + 1)\n",
    "qs0 = qs.copy()\n",
    "for lag in tlags_0: \n",
    "    qs0 = qs0.with_column(Column(column + '_' + str(lag), from_table = table, from_column=column)\n",
    "                        .transform.missing.replace_na()\n",
    "                        .transform.temporal.tlag(lag)\n",
    "                       )\n",
    "    \n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'df_pgm_historical_values_0.parquet'\n",
    "df_pgm_historical_values_0 = retrieve_qs(qs_to_retrieve=qs0,rerun = rerun_querysets,filename=filename)\n",
    "\n",
    "#if rerun_querysets:\n",
    "#    df_pgm_historical_values_0 = qs0.publish().fetch().loc[445:492]    \n",
    "#    df_pgm_historical_values_0.to_parquet(filename)\n",
    "#else:\n",
    "#    df_pgm_historical_values_0 = pd.read_parquet(filename)\n",
    "\n",
    "# Spatial lags, first-order:\n",
    "print('Retrieving data for first-order neighbors')\n",
    "\n",
    "kernel_inner=1\n",
    "kernel_width=1\n",
    "kernel_power=0\n",
    "norm_kernel=0\n",
    "\n",
    "tlags_1=range(1,tlags_firstorder + 1)\n",
    "qs1 = qs.copy()\n",
    "for lag in tlags_1:\n",
    "    qs1 = qs1.with_column(Column(column + '_splag_1_' + str(lag), from_table = table, from_column=column)\n",
    "                        .transform.missing.replace_na()\n",
    "                        .transform.temporal.tlag(lag)\n",
    "                        .transform.spatial.lag(kernel_inner,kernel_width,kernel_power,norm_kernel)\n",
    "                       )\n",
    "\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'df_pgm_historical_values_1.parquet'\n",
    "#df_pgm_historical_values_1 = qs1.publish().fetch().loc[445:492]\n",
    "df_pgm_historical_values_1 = retrieve_qs(qs_to_retrieve=qs1,rerun = rerun_querysets,filename=filename)\n",
    "\n",
    "# Spatial lags; second-order:\n",
    "print('Retrieving data for second-order neighbors')\n",
    "\n",
    "kernel_inner=2\n",
    "kernel_width=1\n",
    "kernel_power=0\n",
    "norm_kernel=0\n",
    "\n",
    "tlags_2=range(1,tlags_secondorder + 1)\n",
    "qs2 = qs.copy()\n",
    "for lag in tlags_2:\n",
    "    qs2 = qs2.with_column(Column(column + '_splag_2_' + str(lag), from_table = table, from_column=column)\n",
    "                        .transform.missing.replace_na()\n",
    "                        .transform.temporal.tlag(lag)\n",
    "                        .transform.spatial.lag(kernel_inner,kernel_width,kernel_power,norm_kernel)\n",
    "                       )\n",
    "\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'df_pgm_historical_values_2.parquet'\n",
    "df_pgm_historical_values_2 = retrieve_qs(qs_to_retrieve=qs2,rerun = rerun_querysets,filename=filename)\n",
    "\n",
    "#df_pgm_historical_values_2 = qs2.publish().fetch().loc[445:492]\n",
    "print('Done retrieving data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96aabc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_historical_values_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5ccd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the data frames\n",
    "df_pgm_historical_values = pd.concat([df_pgm_historical_values_0, df_pgm_historical_values_1, df_pgm_historical_values_2], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2ee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_historical_values = df_pgm_historical_values.loc[445:492]\n",
    "# Computing averages from sums\n",
    "for lag in tlags_1:\n",
    "    col = column + '_splag_1_' + str(lag)\n",
    "    df_pgm_historical_values[col] = df_pgm_historical_values[col]\n",
    "for lag in tlags_2:\n",
    "    col = column + '_splag_2_' + str(lag)\n",
    "    df_pgm_historical_values[col] = df_pgm_historical_values[col]\n",
    "\n",
    "\n",
    "\n",
    "df_pgm_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f798f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pgm_historical_values_2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf44b948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating predictions for test partition\n",
    "number_of_lags_inner = 24\n",
    "number_of_lags_1 = 12\n",
    "number_of_lags_2 = 6\n",
    "maxstep = 14\n",
    "df_list_bystep = []\n",
    "for step in range(3,maxstep+1):\n",
    "    lags=range(step,number_of_lags_inner+step)\n",
    "    draw = 1\n",
    "#    print('step:',step,'lag:',lag, 'draw:',draw)\n",
    "    df_list = []\n",
    "    for lag in lags:\n",
    "        for coltype in [('ged_sb_best_sum_nokgi_',number_of_lags_inner),('ged_sb_best_sum_nokgi_splag_1_',number_of_lags_1),('ged_sb_best_sum_nokgi_splag_2_',number_of_lags_2)]:\n",
    "            number_of_repetitions = coltype[1]+step-lag\n",
    "            for repetition in range(1,number_of_repetitions+1):\n",
    "                if lag <= coltype[1] + step:\n",
    "                    lagged_col = coltype[0] + str(lag)\n",
    "#                    print('draw:',draw, 'step:', step, 'lag:',lag,'repetition:', repetition, 'colname:', lagged_col)\n",
    "                    df = pd.DataFrame(df_pgm_historical_values[lagged_col].copy())\n",
    "                    df.reset_index(inplace=True)\n",
    "                    df['prediction'] = df[lagged_col].astype('int32')\n",
    "                    df.drop(columns=[lagged_col], inplace=True)\n",
    "                    df['step'] = step\n",
    "                    df['draw'] = draw\n",
    "                    df.set_index(['month_id', 'priogrid_gid', 'step','draw'], inplace=True)\n",
    "                    df_list.append(df)\n",
    "                    draw = draw + 1\n",
    "    print('Concatenating', draw-1, 'repetitions for step', step)\n",
    "    df_pgm_predictions_lag = pd.concat(df_list)\n",
    "    df_list_bystep.append(df_pgm_predictions_lag)\n",
    "    \n",
    "#df_pgm_predictions_historical_values = pd.concat(df_list_bystep) \n",
    "#df_pgm_predictions_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff56a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_bystep[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8430a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating sc prediction files for historical values model -- step by step\n",
    "step = 3\n",
    "df_sc_bystep = [[],[],[],[]]\n",
    "for step_df in df_list_bystep:\n",
    "    print('step:', step)\n",
    "    pgm_hv_step = from_ss48_to_sc12(step_df,'pgm2',445,4)\n",
    "    per = 0\n",
    "    for period in pgm_hv_step:\n",
    "        df_sc_bystep[per].append(pgm_hv_step[per])\n",
    "        per += 1\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014ade91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Aggregating')\n",
    "pgm_historical_values_predictions = [[],[],[],[]]\n",
    "for period in range(0,4):\n",
    "    pgm_historical_values_predictions[period] = pd.concat(df_sc_bystep[period]) \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the annual sc files and the aggregated versions of them\n",
    "filepath = Mydropbox + 'Prediction_competition_2023/'\n",
    "year = 2018\n",
    "for df in pgm_historical_values_predictions:\n",
    "    filename = filepath + 'bm_pgm_historical_values_' + str(year) + '.parquet'\n",
    "    print(filename)\n",
    "    df.to_parquet(filename)\n",
    "    df_aggregated = aggregate_and_categorize(df,'pgm')\n",
    "    filename = filepath + 'bm_pgm_historical_values_agg' + str(year) + '.parquet'\n",
    "    df_aggregated.to_parquet(filename)\n",
    "    year = year + 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2f569a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pgm_historical_values_predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56ec044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating step-level dataframes\n",
    "single_file = False\n",
    "\n",
    "if single_file:\n",
    "    df_pgm_predictions_historical_values = df_list_bystep[0]\n",
    "    list_item = 1\n",
    "    for step in range(3+1,maxstep+1):\n",
    "        print('adding data for step', step)\n",
    "        df_pgm_predictions_historical_values = pd.concat([df_pgm_predictions_historical_values,df_list_bystep[list_item]])\n",
    "        list_item += 1\n",
    "\n",
    "    df_pgm_predictions_historical_values.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccedd48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5443cb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe with actuals\n",
    "df_actuals_pgm = pd.DataFrame(df_pgm_historical_values_0['ged_sb'])\n",
    "print(df_actuals_pgm.head())\n",
    "print(df_actuals_pgm.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8e15c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_actuals.parquet'\n",
    "df_actuals_pgm.to_parquet(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659a3194",
   "metadata": {},
   "source": [
    "# Probably obsolete from here.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5055daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate across draws/samples to extract means, standard deviations, and category probabilities\n",
    "# export to parquet step by step\n",
    "step = 3\n",
    "for df in df_list_bystep:\n",
    "    print(step)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_historical_values_step_' + str(step) + '.parquet'\n",
    "    df.to_parquet(filename)\n",
    "    filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_historical_values_step_' + str(step) + '_aggregated.parquet'\n",
    "    df_aggregated = aggregate_and_categorize(df,'pgm')\n",
    "    df_aggregated.to_parquet(filename)\n",
    "\n",
    "    print(df_aggregated.describe())\n",
    "    print(df_aggregated.mean())\n",
    "        \n",
    "    step = step+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d69f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_historical_values.parquet'\n",
    "df_from_file = pd.read_parquet(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86c597f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = Mydropbox + 'Prediction_competition_2023/' + 'pgm_benchmark_historical_values_step_3.parquet'\n",
    "df_from_file = pd.read_parquet(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c6631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74afc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
